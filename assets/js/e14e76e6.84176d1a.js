"use strict";(self.webpackChunkdocusaurus_documentation=self.webpackChunkdocusaurus_documentation||[]).push([[2717],{4168:e=>{e.exports=JSON.parse('{"blogPosts":[{"id":"/2025/12/24/Avoiding-Double-L7-Trap","metadata":{"permalink":"/docs/blog/2025/12/24/Avoiding-Double-L7-Trap","source":"@site/blog/2025-12-24-Avoiding-Double-L7-Trap.md","title":"ALB vs NLB for Istio - Avoiding the Double L7 Trap","description":"Understanding L4 vs L7 Load Balancing in a Service Mesh","date":"2025-12-26T00:00:00.000Z","formattedDate":"December 26, 2025","tags":[{"label":"istio","permalink":"/docs/blog/tags/istio"},{"label":"service-mesh","permalink":"/docs/blog/tags/service-mesh"},{"label":"kubernetes","permalink":"/docs/blog/tags/kubernetes"},{"label":"eks","permalink":"/docs/blog/tags/eks"},{"label":"aws","permalink":"/docs/blog/tags/aws"},{"label":"nlb","permalink":"/docs/blog/tags/nlb"},{"label":"alb","permalink":"/docs/blog/tags/alb"},{"label":"load-balancer","permalink":"/docs/blog/tags/load-balancer"},{"label":"l4-vs-l7","permalink":"/docs/blog/tags/l-4-vs-l-7"},{"label":"cloud-architecture","permalink":"/docs/blog/tags/cloud-architecture"},{"label":"platform-engineering","permalink":"/docs/blog/tags/platform-engineering"},{"label":"microservices","permalink":"/docs/blog/tags/microservices"}],"readingTime":2.76,"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"ALB vs NLB for Istio - Avoiding the Double L7 Trap","description":"Understanding L4 vs L7 Load Balancing in a Service Mesh","image":"https://www.wedaa.tech/docs/img/blog/ALBvsNLBIstio/ALBvsNLB_network_analogy.png","tags":["istio","service-mesh","kubernetes","eks","aws","nlb","alb","load-balancer","l4-vs-l7","cloud-architecture","platform-engineering","microservices"],"date":"2025-12-26T00:00:00.000Z"},"unlisted":false,"nextItem":{"title":"How WeDAA Beat Load Balancer Limits Using Kong API Gateway","permalink":"/docs/blog/2025/04/08/kong-apigateway"}},"content":"## Introduction\\n\\nWhen running **Istio** on Kubernetes (especially on **AWS EKS**), a common question is:\\n\\n> Should I put an **Application Load Balancer (ALB)** or a **Network Load Balancer (NLB)** in front of Istio?\\n\\n![Istio on Kubernetes with load balancers](/img/blog/ALBvsNLBIstio/Istio_on_k8s_with_elb.png)\\n\\nAt first glance, both seem to work. Traffic reaches the cluster and the application responds.  \\nBut once you understand **Layer 4 vs Layer 7** and how a **service mesh** is designed, the right choice becomes clear.\\n\\nThis post explains **why NLB fits Istio better than ALB** and how using ALB can lead to a **double L7 anti-pattern**.\\n\\n---\\n\\n## L4 vs L7 (Only What Matters)\\n\\n### Layer 4 (Transport Layer)\\nLayer 4 is about **connections**, not requests.\\n\\nIt understands:\\n- TCP / UDP\\n- IP addresses and ports\\n\\nIt does *not* understand:\\n- HTTP paths\\n- Headers\\n- Hostnames\\n\\nExample:\\n```\\nConnect to 10.0.1.5:443\\n```\\n\\n\u27a1\ufe0f **AWS NLB works at Layer 4**\\n\\n---\\n\\n### Layer 7 (Application Layer)\\nLayer 7 understands **what the request means**.\\n\\nIt understands:\\n- HTTP / HTTPS / gRPC\\n- Paths like `/api/orders`\\n- Hosts like `app.example.com`\\n- Headers, retries, timeouts\\n\\nExample:\\n```\\nGET /api/orders\\n```\\n\\n\u27a1\ufe0f **Istio (Envoy) works at Layer 7**  \\n\u27a1\ufe0f **AWS ALB also works at Layer 7**\\n\\n---\\n\\n## What Istio Expects\\n\\nIstio is a **service mesh**, not just a proxy.\\n\\nIt controls:\\n- Routing\\n- Traffic splitting\\n- Retries and timeouts\\n- mTLS and security policies\\n- Observability\\n\\nAll of this requires **Layer 7 context**.\\n\\nSo the key idea is:\\n\\n> **Istio expects to be the single Layer 7 decision-maker.**\\n\\n---\\n\\n## ALB + Istio: The Double L7 Trap\\n\\n```\\nClient\\n   \u2193\\nALB (L7)\\n   \u2193\\nIstio Envoy (L7)\\n   \u2193\\nApplication\\n```\\n\\n\\nHere\u2019s the problem:\\n- ALB inspects and routes HTTP\\n- Istio inspects and routes HTTP again\\n- Routing logic is split across two systems\\n- Health checks often conflict\\n- TLS is usually terminated before Istio\\n\\nThis creates unnecessary complexity and confusion.\\n\\n---\\n\\n## NLB + Istio: Clean Separation\\n\\n```\\nClient\\n   \u2193\\nNLB (L4)\\n   \u2193\\nIstio Envoy (L7)\\n   \u2193\\nApplication\\n```\\n\\nWith this setup:\\n- NLB only forwards TCP traffic\\n- Istio handles all HTTP logic\\n- No overlapping responsibilities\\n- Cleaner security and observability\\n- Fewer edge-case failures\\n\\nThis is the **service-mesh-native design**.\\n\\n![ALB vs NLB with Istio \u2014 Avoiding the Double L7 Trap](/img/blog/ALBvsNLBIstio/ALBvsNLB.png)\\n\\n*Left: ALB + Istio introduces two Layer-7 decision points (the Double L7 Trap).  \\nRight: NLB forwards at Layer-4 while Istio remains the single Layer-7 authority.*\\n\\n---\\n\\n## Simple Analogy\\n\\n![ALB vs NLB network analogy](/img/blog/ALBvsNLBIstio/ALBvsNLB_network_analogy.png)\\n\\n**ALB + Istio**  \\n> Two traffic cops trying to control the same intersection.\\n\\n**NLB + Istio**  \\n> One tunnel (NLB) and one traffic cop (Istio).\\n\\n---\\n\\n## When ALB Can Still Make Sense\\n\\nALB is fine if:\\n- You are not using Istio for ingress routing\\n- You want AWS-managed L7 routing at the edge\\n- Istio is used only for internal service-to-service traffic\\n\\nBut if Istio manages ingress traffic, ALB becomes redundant.\\n\\n---\\n## Final Recommendation\\n\\n![End-End Request Flow](/img/blog/ALBvsNLBIstio/request-flow.png)\\n\\nFor Istio on EKS:\\n\\n- \u2705 Use **NLB (Layer 4)**\\n- \u2705 Let **Istio control Layer 7**\\n- \u274c Avoid **ALB + Istio ingress**\\n\\n---\\n## Key Takeaway\\n\\n> **A service mesh needs one Layer 7 brain.**  \\n> **Everything before it should stay simple and dumb.**\\n\\nThat\u2019s why **NLB works best with Istio**."},{"id":"/2025/04/08/kong-apigateway","metadata":{"permalink":"/docs/blog/2025/04/08/kong-apigateway","source":"@site/blog/2025-04-08-kong-apigateway.md","title":"How WeDAA Beat Load Balancer Limits Using Kong API Gateway","description":"How WeDAA Beat Load Balancer Limits Using Kong API Gateway","date":"2025-05-29T00:00:00.000Z","formattedDate":"May 29, 2025","tags":[{"label":"microservices","permalink":"/docs/blog/tags/microservices"},{"label":"architecture","permalink":"/docs/blog/tags/architecture"},{"label":"api gateway","permalink":"/docs/blog/tags/api-gateway"},{"label":"kong gateway","permalink":"/docs/blog/tags/kong-gateway"},{"label":"load balancer","permalink":"/docs/blog/tags/load-balancer"},{"label":"hetzner","permalink":"/docs/blog/tags/hetzner"},{"label":"path based routing","permalink":"/docs/blog/tags/path-based-routing"},{"label":"cloud infrastructure","permalink":"/docs/blog/tags/cloud-infrastructure"},{"label":"scaling microservices","permalink":"/docs/blog/tags/scaling-microservices"},{"label":"cloud cost optimization","permalink":"/docs/blog/tags/cloud-cost-optimization"},{"label":"infrastructure challenges","permalink":"/docs/blog/tags/infrastructure-challenges"},{"label":"backend architecture","permalink":"/docs/blog/tags/backend-architecture"},{"label":"platform engineering","permalink":"/docs/blog/tags/platform-engineering"},{"label":"api management","permalink":"/docs/blog/tags/api-management"}],"readingTime":4.4,"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"How WeDAA Beat Load Balancer Limits Using Kong API Gateway","description":"How WeDAA Beat Load Balancer Limits Using Kong API Gateway","image":"https://i.imgur.com/kbgl7U1.png","tags":["microservices","architecture","api gateway","kong gateway","load balancer","hetzner","path based routing","cloud infrastructure","scaling microservices","cloud cost optimization","infrastructure challenges","backend architecture","platform engineering","api management"],"date":"2025-05-29T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"ALB vs NLB for Istio - Avoiding the Double L7 Trap","permalink":"/docs/blog/2025/12/24/Avoiding-Double-L7-Trap"},"nextItem":{"title":"Bulkhead Pattern -> Cell based architecture","permalink":"/docs/blog/2024/05/05/Bulkhead-Pattern"}},"content":"## Introduction\\n\\nWe\'re [WeDAA](https://www.wedaa.tech/), short for Well Defined Application Architecture\u2014a platform that empowers developers and architects to visually prototype software architectures on a canvas. Whether you\'re building enterprise applications, startup MVPs, or incubating new ideas, WeDAA helps you bootstrap non-functional requirements like APIs, microservices, and infrastructure in minutes instead of days.\\n\\nEverything was going smoothly\u2014until we hit a hard limit. Our hosting provider, Hetzner, imposed a frustrating restriction: their load balancers only allow five service mappings. For a platform like ours that depends on running dozens of services, this was a serious roadblock.\\n\\n**Spoiler alert**: Kong API Gateway came to our rescue. Here\u2019s how we turned a rigid infrastructure limitation into a streamlined, scalable solution.\\n\\n![WeDAA GATEWAY](/img/blog/kong-apigateway/intro.png)\\n\\n## The Backstory: What\u2019s WeDAA Anyway?\\n\\n#### A Visual Platform for Modern Architecture\\n[WeDAA](https://www.wedaa.tech/) is like a LEGO set for software architecture\u2014developers can visually design, connect, and deploy microservices without the heavy lifting of backend setup. It handles the non-functional groundwork so you can focus on building features.\\n\\n#### Our Cloud of Choice: Hetzner\\n\\n![Hetzner](/img/blog/kong-apigateway/hetzner.png)\\n\\nWhen we launched, we chose [Hetzner](https://www.hetzner.com/) for hosting. It\u2019s fast, reliable, and super budget-friendly\u2014which is a big deal when you\'re bootstrapping or scaling quickly.\\n\\n#### Why Hetzner? Cost vs Features\\nFor the price, Hetzner rocks. But not everything that glitters is gold. While compute and storage were amazing, their load balancer offering had\u2026 well, \u201cquirks.\u201d\\n\\n## Enter the Challenge: Microservices Meet Their Limit\\n\\n#### WeDAA\u2019s Need for Scalability\\nAs a microservices platform, WeDAA doesn\u2019t run one or two services\u2014we run dozens, sometimes more. Each service typically needs to be exposed externally or internally in a managed way.\\n\\n#### Load Balancers and Path-Based Routing: What\u2019s the Deal?\\n\\nNormally, you\u2019d use a path-based routing strategy. \\n\\n![Path-based routing strategy](/img/blog/kong-apigateway/path-based-routing.png)\\n\\nLike this:\\n\\n- `/auth` \u2192 Authentication Service\\n\\n- `/billing` \u2192 Billing Service\\n\\n- `/notifications` \u2192 Notification Service\\n\\nSimple, clean, and only one public-facing endpoint required.\\n\\n#### Hetzner\u2019s Load Balancer Limitation\\nBut here\u2019s where it broke down: Hetzner\u2019s load balancers don\u2019t support path-based routing. Oof.\\n\\nOnly 5 Port Mappings? Seriously?\\nInstead, you have to map services by port. So if your LB is lb11, you can only do stuff like:\\n\\n- Port 8080 \u2192 Auth\\n\\n- Port 8081 \u2192 Billing\\n\\n- Port 8082 \u2192 Notifications\\n\\n...and so on\u2014but only 5 of these mappings allowed.\\n\\n## Load Balancer Bottleneck: Our Initial Struggle\\n\\n#### Trying to Squeeze Multiple Services Behind One LB\\nYou can see where this is going. We had way more than 5 services.\\n\\n#### Options We Considered\\n\\nWe brainstormed all possible hacks:\\n\\n- Buy a bigger load balancer (was an option\u2014but the cost jumped fast)\\n\\n- Spin up more LBs (costly and messy)\\n\\n- Use a reverse proxy manually (yikes\u2014complex maintenance)\\n\\n#### All Roads Led to Cost & Complexity\\n\\nEvery workaround added either cost, technical debt, or overhead. We needed something smarter\u2014a gateway between our load balancer and services.\\n\\n## Discovering a Smarter Way: Say Hello to Kong API Gateway\\n\\n![Kong API Gateway](https://miro.medium.com/v2/resize:fit:1020/1*vi1keg-mSEHuQCMcPK_orw.png)\\n\\n#### What is Kong API Gateway, Anyway?\\n\\n[Kong Gateway](https://docs.konghq.com/gateway/3.10.x/get-started/) is a lightweight, fast, and flexible cloud-native API gateway. Kong Gateway sits in front of your service applications, dynamically controlling, analyzing, and routing requests and responses. Kong Gateway implements your API traffic policies by using a flexible, low-code, plugin-based approach.\\n\\nIt\'s like a digital traffic cop that decides where to send API requests based on path, headers, method\u2014you name it.\\n\\n#### How Kong Helped Us Bypass LB Limitations\\nWith Kong sitting behind the load balancer, we only needed to expose one service\u2014Kong itself. Then Kong handled internal routing to all our microservices based on the URL path.\\n\\n#### One Service, Multiple Paths\\nBoom. Now instead of mapping 5 different ports on the LB, we had:\\n\\n- lb11:443 \u2192 Kong\\n\\n    - `/auth`          \u2192 Auth Service\\n    - `/billing`       \u2192 Billing Service\\n    - `/notifications` \u2192 Notification Service\\n    - `/anything`      \u2192 Any Service We Wanted\\n\\n#### Internal Routing Made Simple\\nAll services were registered with Kong. We configured routing rules, and it took care of the rest. No extra LBs. No extra cost.\\n\\n\\n## A Real-World Architecture Shift\\n#### Before Kong: Chaos\\nDozens of services, all needing public access, but limited to 5. It was like trying to stuff an elephant into a mini-fridge.\\n\\n#### After Kong: Clarity\\n\\nNow it\u2019s:\\n\\nHetzner LB \u2192 Kong \u2192 All internal microservices\\n\\n```\\n[Internet] \u2192 [Hetzner LB] \u2192 [Kong API Gateway] \u2192 [Service A, B, C...Z]\\n```\\n\\nClean, scalable, and way easier to manage.\\n\\n## Would We Do It Again? 100% Yes\\n\\n![Hetzner](/img/blog/kong-apigateway/developer.png)\\n\\n#### Scalability Without Extra Costs\\n- We\u2019re saving $$$ by not buying extra load balancers.\\n\\n#### Future-Proofing the Platform\\n- Need to add 10 more services? 50? No problem\u2014Kong\u2019s got it.\\n\\n#### Faster Deployments\\n- New service? Register with Kong, deploy, and done. No port juggling.\\n\\n## Wrapping Up: Kong API Gateway \u2013 Game-Changer in Our Stack\\n\\nIf you\'re running multiple services and your cloud provider\u2019s load balancer has limitations, Kong can help. It did the job for us\u2014quickly and without adding complexity.\\n\\nWhat started as a problem with too many services turned into a simple solution. Now, Kong is a key part of our setup\u2014and we\u2019re not looking back.\\n\\n*\ud83d\udc49 In our next blog, we\u2019ll show you how to configure Kong API Gateway and use it in your microservices architecture step by step\u2014stay tuned!*"},{"id":"/2024/05/05/Bulkhead-Pattern","metadata":{"permalink":"/docs/blog/2024/05/05/Bulkhead-Pattern","source":"@site/blog/2024-05-05-Bulkhead-Pattern.md","title":"Bulkhead Pattern -> Cell based architecture","description":"Understanding cell based architecture","date":"2024-05-05T00:00:00.000Z","formattedDate":"May 5, 2024","tags":[{"label":"microservices","permalink":"/docs/blog/tags/microservices"},{"label":"architecture","permalink":"/docs/blog/tags/architecture"}],"readingTime":3.285,"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"Bulkhead Pattern -> Cell based architecture","description":"Understanding cell based architecture","image":"https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2fea266d-829c-4dad-955a-c6905360448a_800x500.png","tags":["microservices","architecture"],"date":"2024-05-05T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"How WeDAA Beat Load Balancer Limits Using Kong API Gateway","permalink":"/docs/blog/2025/04/08/kong-apigateway"},"nextItem":{"title":"Definitive Guide to Knative Serving\u2014A Deep Dive into Theory and Architecture","permalink":"/docs/blog/2024/05/01/knative-serving-01"}},"content":"## Cell based architecture\\n\\n![Cell based architecture](/img/blog/bulkhead-pattern/00-cell-based-architecture.png)\\n\\nBulkhead or Cell-based architecture is an architectural pattern adopted for constructing highly available, scalable, and fault-tolerant enterprise applications.\\n\\nThe concept of the bulkhead pattern draws inspiration from the architecture of ship hulls, wherein the hull is divided into multiple cells or sections to prevent the entire ship from sinking if one section is damaged.\\n\\n![ship hulls](/img/blog/bulkhead-pattern/01-ship-hulls.png)<p align=\\"center\\">Vertical Partitioning of Walls dividing the Ship\u2019s hull</p>\\n\\n\\nIn the bulkhead architecture approach, ships manage the risk of sinking by isolating compromised compartments. The vertical partitioning of walls divides the ship\'s interior into self-contained, watertight compartments, aiming to contain a hull breach within a specific section of the ship.\\n\\nA similar concept is applied when designing scalable enterprise applications having dynamic workload, known as cell-based architecture.\\n\\n## Key Components of Cell Based Architecture\\n\\n### Cell Router\\n\\n![Cell Router](/img/blog/bulkhead-pattern/02-cell-router.png)\\n\\nA cell router is a key component in a cell-based architecture. Traffic to every individual cell is routed through cell router. If a cell fails, only the traffic directed to that cell will be impacted. In short impact on the system will be minimal. The cell router is responsible for receiving the request, determining their destination based on cell partitioning algorithms, and then forwarding them towards the destination cell.\\n\\n### Blast Radius\\n\\n![Blast Radius](/img/blog/bulkhead-pattern/03-blast-radius.png)\\n\\nRepresents the area or range of systems, components, or processes that may be affected directly or indirectly by a single cell failure event. For example, if a system is built with four cells and any service in a cell goes down only the 25% of traffic will be affected. So, the blast radius is approximate 25% here.\\n\\n### Traffic distribution\\n\\nCell router plays a critical role in orchestrating traffic distribution among cells in cell-based architecture. Traffic distribution works by routing incoming requests to the appropriate cell or service instance based on predefined routing rules or policies. The cells get partitioned using a partition key. A simple or composite partition key can be used to distribute the traffic between cells. the partitioning strategy could be ranging partitioning, hash partitioning, or list partitioning. The chosen partitioning strategy will influence how the partition key is used to distribute traffic across partitions.\\n\\n### Self-Contained Unit (Cell)\\n\\n![Self-Contained Unit (Cell)](/img/blog/bulkhead-pattern/04-cell.png)\\n\\nComplete in itself modules are the first-class citizen of any cell-based architecture. Such modules are the one which serves the logical / business purpose of a feature or service along with non-functional entities around it. Such as API\u2019s, load balancer and database. In short, a cell in a cell-based architecture is self-contained and self- sustainable instance of an application which can be deployed, scaled, and observed independently. Cells are isolated with each other at logical level, failure of a cell does not affect other cells and reduces the overall impact to software. With the cell-based architecture a cell does not share encompassed services state with other cells in the system.\\n\\n### Cell Health Check\\n\\nBefore forwarding the request, the cell router layer may perform health checks on the target cell or service instance to ensure that cell can handle the request. If the target instance is unhealthy or unavailable, the router may reroute the request to a healthy cell or trigger automatic recovery mechanisms.\\n\\n### Database Replication\\n\\n![Database Replication](/img/blog/bulkhead-pattern/05-db-replication.png)\\n\\nIn cell-based architecture Database replication is used to synchronize data between cells to ensure consistency and availability. Changes made to data in one cell need to be propagated to other cells where that data is relevant. Replication mechanisms vary based on the specific database technology used, but they involve replicating data changes asynchronously or semi-synchronously between cells.\\n\\n## When to use Cell Based Architecture?\\n\\nFor systems that require high scalability and the ability to handle large volumes of traffic, cell-based architecture allows for horizontal scaling by adding more cells as needed.\\n\\nApplications with dynamic workloads that require rapid scaling up or down based on demand, cell-based architecture provides the flexibility to scale individual cells independently, optimizing resource utilization."},{"id":"/2024/05/01/knative-serving-01","metadata":{"permalink":"/docs/blog/2024/05/01/knative-serving-01","source":"@site/blog/2024-05-01-knative-serving-01.md","title":"Definitive Guide to Knative Serving\u2014A Deep Dive into Theory and Architecture","description":"A Deep Dive into Theory and Architecture of Knative Serving","date":"2024-05-01T00:00:00.000Z","formattedDate":"May 1, 2024","tags":[{"label":"microservices","permalink":"/docs/blog/tags/microservices"},{"label":"architecture","permalink":"/docs/blog/tags/architecture"},{"label":"cloud-native","permalink":"/docs/blog/tags/cloud-native"},{"label":"Serverless","permalink":"/docs/blog/tags/serverless"},{"label":"cloud computing","permalink":"/docs/blog/tags/cloud-computing"},{"label":"knative","permalink":"/docs/blog/tags/knative"},{"label":"kubernetes","permalink":"/docs/blog/tags/kubernetes"},{"label":"Knative-serving","permalink":"/docs/blog/tags/knative-serving"}],"readingTime":9.985,"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"Definitive Guide to Knative Serving\u2014A Deep Dive into Theory and Architecture","description":"A Deep Dive into Theory and Architecture of Knative Serving","image":"https://www.wedaa.tech/docs/img/blog/knative-serving-01/00-overview.png","tags":["microservices","architecture","cloud-native","Serverless","cloud computing","knative","kubernetes","Knative-serving"],"date":"2024-05-01T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"Bulkhead Pattern -> Cell based architecture","permalink":"/docs/blog/2024/05/05/Bulkhead-Pattern"},"nextItem":{"title":"Revolutionizing Software Development with React Flow","permalink":"/docs/blog/2024/04/25/react-flow"}},"content":"If you missed the first installment of our Knative series, you can catch up by diving into our previous blog post:\\n[Dive into Knative\u2014Explore Serverless with Kubernetes](https://www.wedaa.tech/docs/blog/2024/04/13/overview-on-knative)\\n\\n## Overview\\n![Overview](/img/blog/knative-serving-01/00-overview.png)<p align=\\"center\\">[Technology Conversations](https://technologyconversations.com/2020/08/19/serverless-computing-with-knative-and-containers-as-a-service-caas/)</p>\\n\\nThe key aspects and benefits of Knative Serving:\\n\\n1. **Serverless Platform**: Knative Serving is a serverless platform built on top of Kubernetes.\\n2. **Deployment Simplification**: It simplifies the deployment of containerized applications on Kubernetes.\\n3. **Auto-scaling**: Automatically scales applications based on demand, ensuring optimal resource utilization.\\n4. **Traffic Management**: Provides features for managing traffic routing, allowing seamless updates and rollbacks.\\n5. **Focus on Development**: Abstracts away infrastructure management complexities, enabling developers to focus on writing and deploying code.\\n6. **Cloud-Native Applications**: Facilitates the development of modern, scalable, and resilient cloud-native applications.\\n\\nFor an introductory exploration of Knative Serving, delve into our dedicated [Knative Serving](https://www.wedaa.tech/docs/blog/2024/04/13/overview-on-knative#knative-serving) section.\\n\\n## Knative Serving Architecture\\n\\n### Architecture Diagram\\n\\nKnative Serving consists of several components forming the backbone of the Serverless Platform. This blog explains the high-level architecture of Knative Serving. \\n\\n![Architecture](/img/blog/knative-serving-01/01-architecture.png)\\n\\n### Components\\n\\n- **Activator**: The activator is part of the [data-plane]. It is responsible to queue incoming requests (if a Knative Service is scaled-to-zero). It communicates with the autoscaler to bring scaled-to-zero Services back up and forward the queued requests. Activator can also act as a request buffer to handle traffic bursts.\\n- **Autoscaler**: The autoscaler is responsible to scale the Knative Services based on configuration, metrics and incoming requests.\\n- **Controller**: The controller manages the state of Knative resources within the cluster. It watches several objects, manages the lifecycle of dependent     resources, and updates the resource state.\\n- **Queue-Proxy**:\\tThe Queue-Proxy is a sidecar container in the Knative Service\'s Pod. It is responsible to collect metrics and enforcing the desired concurrency when forwarding requests to the user\'s container. It can also act as a queue if necessary, similar to the Activator.\\n- **Webhooks**:\\tKnative Serving has several webhooks responsible to validate and mutate Knative Resources.\\n\\n### HTTP Request Flows\\nThis explains the behavior and flow of HTTP requests to an application which is running on Knative Serving.\\n\\n![HTTP Request Flows](/img/blog/knative-serving-01/02-http-request-flow.png)\\n\\n1. **Initial Request**: When a user sends an HTTP request to your Knative service, it first hits the ingress gateway.\\n2. **Routing Decision**: The ingress gateway examines the request to determine which Knative service should handle it based on the requested domain name.\\n3. **Service Activation**: Knative Serving keeps your service deployed at all times. When a request arrives and no instances are running, it promptly activates a new instance by spinning up a pod.\\n4. **Scaling Decision**: Knative Serving checks the current load and decides how many instances of the service need to be running to handle incoming requests efficiently.\\n5. **Activator Interaction**: For the first-time request, it goes to the activator. The activator asks the auto scaler to scale up one pod to serve the initial request, ensuring rapid response and availability.\\n6. **Request Handling**: The request is then forwarded to one of the instances of your service, where your application code processes it.\\n7. **Containerized Environment**: Within each pod, there are two containers:\\n    - User Container: This container hosts your application code, serving user requests.\\n    - Queue Container: This container monitors metrics and observes concurrency levels.\\n8. **Auto-scaling Based on Concurrency**: When the concurrency exceeds the default level, the autoscaler spins up new pods to handle the increased concurrent requests, ensuring optimal performance.\\n9. **Response**: After processing the request, your service generates a response, which is sent back through the same flow to the user who made the initial request.\\n10. **Scaling Down**: If there is no more traffic or if the traffic decreases significantly, Knative Serving may scale down the number of running instances to save resources.\\n\\n\x3c!-- In essence, Knative Serving orchestrates the lifecycle of your service instances, ensuring they are available to handle incoming requests, dynamically scaling them up or down based on demand, and managing traffic routing seamlessly while optimizing resource utilization. --\x3e\\n### Revisions\\n- Revisions are Knative Serving resources representing snapshots of application code and configuration.\\n- They are created automatically in response to updates in a Configuration spec.\\n- Revisions cannot be directly created or updated; they are managed through Configuration changes.\\n- Deletion of Revisions can be forced to handle resource leaks or remove problematic Revisions.\\n- Revisions are generally immutable, but may reference mutable Kubernetes resources like ConfigMaps and Secrets.\\n- Changes in Revision defaults can lead to syntactic mutations in Revisions, affecting configuration without altering their core behavior.\\n\\n### Autoscaling\\n![Kubernetes Autoscaling Options](/img/blog/knative-serving-01/03-autoscaling.png)<p align=\\"center\\">[Kubernetes Autoscaling Options](https://platform9.com/blog/kubernetes-autoscaling-options-horizontal-pod-autoscaler-vertical-pod-autoscaler-and-cluster-autoscaler/)</p>\\n\\nKnative Serving provides automatic scaling, or autoscaling, for applications to match incoming demand. This is provided by default, by using the Knative Pod Autoscaler (KPA).\\n\\nFor example, if an application is receiving no traffic and scale to zero is enabled, Knative Serving scales the application down to zero replicas. If scaling to zero is disabled, the application is scaled down to the minimum number of replicas specified for applications on the cluster. Replicas are scaled up to meet demand if traffic to the application increases.\\n\\n#### Supported Autoscaler types\\n\\nKnative Serving supports the implementation of Knative Pod Autoscaler (KPA) and Kubernetes\' Horizontal Pod Autoscaler (HPA).\\n\\n- Knative Pod Autoscaler (KPA)\\n    - Part of the Knative Serving core and enabled by default once Knative Serving is installed.\\n    - Supports scale to zero functionality.\\n    - Does not support CPU-based autoscaling.\\n- Horizontal Pod Autoscaler (HPA)\\n    - Not part of the Knative Serving core, and you must install Knative Serving first.\\n    - Does not support scale to zero functionality.\\n    - Supports CPU-based autoscaling.\\n\\n## Knative Serving Autoscaling System\\n\\n### APIs\\n\\n1. **PodAutoscaler** (PA):\\n    - API: `podautoscalers.autoscaling.internal.knative.dev`\\n    - It\'s an abstraction that encompasses all possible PodAutoscalers, with the default implementation being the Knative Pod Autoscaler (KPA).\\n    - The PodAutoscaler manages the `scaling target`, the `metric` used for scaling, and other `relevant inputs` for the autoscaling decision-making process.\\n        1. **Scaling Target**: The PodAutoscaler determines what resource it should scale. This could be the number of pods, CPU utilization, memory consumption, or any other metric that indicates the workload\'s demand.\\n        2. **Metric for Scaling**: It specifies which metric or metrics should be used to make scaling decisions. For example, it might use CPU utilization to decide when to add or remove pods based on workload demand.\\n        3. **Other Inputs**: The PodAutoscaler considers additional factors beyond just the scaling metric. These could include constraints, policies, or thresholds that influence scaling decisions. For instance, it might have rules to prevent scaling beyond a certain limit or to ensure a minimum number of pods are always running.\\n    - PodAutoscalers are automatically created from Revisions by default.\\n2. **Metric**:\\n    - API: `metrics.autoscaling.internal.knative.dev`\\n    - This API controls the collector of the autoscaler, determining which service to scrape data from, how to aggregate it, and other related aspects.\\n        1. **Collector Control**: The API controls the collector component of the autoscaler. The collector is responsible for gathering data related to the performance and behavior of the services being monitored for autoscaling.\\n        2. **Data Scraping**: It determines which service or services the autoscaler should scrape data from. This involves collecting relevant metrics such as CPU utilization, request latency, or throughput from the specified services.\\n        3. **Aggregation**: The API defines how the collected data should be aggregated. This could involve calculating averages, sums, or other statistical measures over a specific time window to provide a meaningful representation of the service\'s performance.\\n        4. **Other Related Aspects**: Beyond data collection and aggregation, the API likely handles other aspects such as data retention policies, thresholds for triggering scaling actions, and configurations for interacting with the autoscaler\'s decision-making process.\\n    - Metrics are automatically generated from PodAutoscalers by default.\\n3. **ServerlessServices** (SKS):\\n    - API: `serverlessservices.networking.internal.knative.dev`\\n    - It\'s an abstraction layer built on top of Kubernetes Services, managing the data flow and the switch between using the activator as a buffer or routing directly to application instances.\\n    - SKS creates two Kubernetes services for each revision: a public service and a private service.\\n    - The private service points to the application instances, while the public service endpoints are managed directly by the SKS reconciler.\\n    - SKS operates in two modes: Serve and Proxy.\\n        1. In **Serve mode**, traffic flows directly to the revision\'s pods.\\n        2. In **Proxy mode**, traffic is directed to activators.\\n    - ServerlessServices are created from PodAutoscalers.\\n\\n### Scaling up and down (steady state)\\n\\n![steady state](/img/blog/knative-serving-01/04-steady-state.png)\\n- **Steady State Operation**:\\n    - The autoscaler operates continuously at a steady state.\\n    - It regularly scrapes data from the currently active revision pods to monitor their performance.\\n- **Dynamic Adjustment**:\\n    - As incoming requests flow into the system, the scraped values of performance metrics change accordingly.\\n    - Based on these changing metrics, the autoscaler dynamically adjusts the scale of the revision.\\n- **SKS Functionality**:\\n    - The ServerlessServices (SKS) component keeps track of changes to the deployment\'s size.\\n    - It achieves this by monitoring the private service associated with the deployment.\\n- **Public Service Update**:\\n    - SKS updates the public service based on the changes detected in the deployment\'s size.\\n    - This ensures that the public service endpoints accurately reflect the available instances of the revision.\\n\\n### Scaling to zero\\n![Scaling to zero](/img/blog/knative-serving-01/05-scaling-to-zero.png)\\n\\n- **Scaling to Zero Process** (1):\\n    - A revision scales down to zero when there are no more requests in the system.\\n    - All data collected by the autoscaler from revision pods and the activator reports zero concurrency, indicating no active requests.\\n- **Activator Preparation**:\\n    - Before removing the last pod of the revision, the system ensures that the activator is in the path and reachable.\\n- **Proxy Mode Activation** (4.1):\\n    - The autoscaler, which initiated the decision to scale to zero, directs the SKS to switch to Proxy mode.\\n    - In Proxy mode, all incoming traffic is routed to the activators.\\n- **Public Service Probing**:\\n    - The SKS\'s public service is probed continuously to ensure it returns responses from the activator.\\n    - Once the public service reliably returns responses from the activator and a configurable grace period (set via scale-to-zero-grace-period) has elapsed,\\n- **Final Scaling Down** (5):\\n    - The last pod of the revision is removed, marking the successful scaling down of the revision to zero instances.\\n\\n### Scaling from zero\\n![Scaling from zero](/img/blog/knative-serving-01/06-scaling-from-zero.png)\\n\\n- **Scaling Up Process**:\\n    - If a revision is scaled to zero and a request arrives for it, the system needs to scale it up.\\n    - As the SKS is in Proxy mode, the request reaches the activator.\\n- **Request Handling**:\\n    - The activator counts the incoming request and reports its appearance to the autoscaler (2.1).\\n    - It then buffers the request and monitors the SKS\'s private service for endpoints to appear (2.2).\\n- **Autoscaling Cycle** (3):\\n    - The autoscaler receives the metric from the activator and initiates an autoscaling cycle.\\n    - This process determines the desired number of pods based on the incoming request.\\n- **Scaling Decision** (4):\\n    - The autoscaling process concludes that at least one pod is needed to handle the incoming request.\\n- **Scaling Up Instructions** (5.1):\\n    - The autoscaler instructs the revision\'s deployment to scale up to N > 0 replicas to accommodate the increased demand.\\n- **Serve Mode Activation** (5.2):\\n    - The autoscaler switches the SKS into Serve mode, directing traffic to the revision\'s pods directly once they are up.\\n- **Endpoint Probing**:\\n    - The activator monitors the SKS\'s private service for the appearance of endpoints.\\n    - Once the endpoints come up and pass the probe successfully, the respective address is considered healthy and used to route the buffered request and any additional requests that arrived in the meantime (8.2).\\n- **Successful Scaling Up**:\\n    - The revision has successfully scaled up from zero to handle the incoming request.\\n\\n## Conclusion\\n\\nIn summary, we\'ve explored the core concepts of Knative Serving, from its architecture to scaling mechanisms. Next, we\'ll dive into practical implementation in our upcoming blog. Also, stay tuned for the integration of the serverless component into the [WeDAA](https://app.wedaa.tech/) Platform, making prototyping and deployment faster and easier than ever."},{"id":"/2024/04/25/react-flow","metadata":{"permalink":"/docs/blog/2024/04/25/react-flow","source":"@site/blog/2024-04-25-react-flow.md","title":"Revolutionizing Software Development with React Flow","description":"Revolutionizing Software Development with React Flow","date":"2024-04-25T00:00:00.000Z","formattedDate":"April 25, 2024","tags":[{"label":"react","permalink":"/docs/blog/tags/react"},{"label":"reactflow","permalink":"/docs/blog/tags/reactflow"},{"label":"bestpractices","permalink":"/docs/blog/tags/bestpractices"}],"readingTime":13.675,"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"Revolutionizing Software Development with React Flow","description":"Revolutionizing Software Development with React Flow","image":"https://user-images.githubusercontent.com/3797215/156259138-fb9f59f8-52f2-474a-b78c-6570867e4ead.svg#gh-light-mode-only","tags":["react","reactflow","bestpractices"],"date":"2024-04-25T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"Definitive Guide to Knative Serving\u2014A Deep Dive into Theory and Architecture","permalink":"/docs/blog/2024/05/01/knative-serving-01"},"nextItem":{"title":"Unveiling the Power of Feature Flags in Software Development","permalink":"/docs/blog/2024/04/18/feature-flags"}},"content":"## React and React Flow\\n\\n![React Flow](/img/blog/react-flow/reactflow-1.png)\\n\\nReact is a popular JavaScript library used for building user interfaces. It allows developers to build reusable components that can be combined to create complex UIs with ease. React Flow is a library built on top of React that provides a set of components for building interactive node-based UIs, such as flowcharts, diagrams, and graphs. In this blog, we will discuss why we used React Flow, its main functions, and what makes it unique.\\n\\n## Why React Flow?\\n\\nReact Flow provides a simple way to create interactive node-based UIs. It\'s built on top of React, which means that it integrates seamlessly with other React components and libraries. Additionally, React Flow is highly customizable, allowing developers to create unique visuals and behaviors for their flowcharts, diagrams, and graphs.\\n\\n## Main Functions of React Flow\\n\\nReact Flow provides a set of core components that can be combined to create powerful and complex node-based UIs. Some of the main functions include:\\n\\n- Drag and drop nodes\\n- Connect nodes with edges\\n- Customizable node appearance and behavior\\n- Zoom and pan\\n- Multiple selection\\n\\n## What Makes React Flow Unique?\\n\\nReact Flow stands out among other libraries for building node-based graphs and diagrams for several reasons:\\n![What Makes React Flow Unique](/img/blog/react-flow/reactflow-2.png)\\n\\n1. **React Integration**: As the name suggests, React Flow is specifically designed for integration with React applications. It leverages React\'s component-based architecture and state management, making it easy for React developers to incorporate complex graph visualization into their projects seamlessly.\\n\\n2. **Customizability**: React Flow offers a high degree of customizability, allowing developers to style and configure every aspect of the graph components to suit their application\'s needs. This includes customization of node appearance, edge styles, interaction behaviors, and more.\\n\\n3. **Performance**: React Flow is optimized for performance, ensuring smooth interactions and efficient rendering even with large graphs containing hundreds or thousands of nodes and edges. It achieves this by employing various optimization techniques such as virtualization and smart rendering.\\n\\n4. **Community and Support**: React Flow has a growing community of users and contributors who actively maintain the library, provide support, and contribute new features and improvements. This means that developers can rely on a robust ecosystem of resources and assistance when working with React Flow in their projects.\\n\\n5. **Rich Feature Set**: React Flow offers a rich feature set out of the box, including support for features like drag-and-drop node placement, automatic layout algorithms, zooming and panning, undo/redo functionality, and more. These features make it suitable for a wide range of graph visualization use cases.\\n\\n6. **Active Development**: The React Flow library is actively developed and updated, meaning that it stays up-to-date with the latest developments in the React ecosystem and continues to receive new features, optimizations, and bug fixes over time.\\n\\nOverall, React Flow\'s combination of React integration, customizability, performance, community support, rich feature set, and active development make it a standout choice for developers looking to incorporate node-based graph visualization into their React applications.\\n\\n## Installation of React Flow\\n\\nPrerequisites:\\n\\n- [Node.js](https://nodejs.org/en/)\\n- [npm](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm) or another package manager like\xa0[yarn](https://yarnpkg.com/)\xa0or\xa0[pnpm](https://pnpm.io/).\\n- A basic knowledge of\xa0[React](https://reactjs.org/).\\n\\nTo get started with React Flow, you first need to install it using npm or yarn. You can do this by running:\\n\\n```\\nnpm install react-flow\\n```\\n\\nor\\n\\n```\\nyarn add react-flow\\n```\\n\\nOnce you\'ve installed React Flow, you can import the core components and start building your node-based UI.\\n\\nHere\'s an example of how to create a simple flowchart using React Flow:\\n\\n```jsx\\nimport React from \\"react\\";\\nimport ReactFlow from \\"reactflow\\";\\n\\nimport \\"reactflow/dist/style.css\\";\\n\\nconst initialNodes = [\\n  { id: \\"1\\", position: { x: 0, y: 0 }, data: { label: \\"1\\" } },\\n  { id: \\"2\\", position: { x: 0, y: 100 }, data: { label: \\"2\\" } },\\n];\\nconst initialEdges = [{ id: \\"e1-2\\", source: \\"1\\", target: \\"2\\" }];\\n\\nexport default function App() {\\n  return (\\n    <div style={{ width: \\"100vw\\", height: \\"100vh\\" }}>\\n      <ReactFlow nodes={initialNodes} edges={initialEdges} />\\n    </div>\\n  );\\n}\\n```\\n\\nIn this example, we\'re importing React and ReactFlow, defining an array of elements that represent our nodes and edges, and rendering a `<ReactFlow>` component with our elements as props.\\n\\nThe\xa0`<ReactFlow />`\xa0component must be wrapped in an element with a width and height.\\n\\n## Want to dive into React Flow?\\nThe above example provides a basic introduction to creating flowcharts with React Flow. However, React Flow offers many more features and customization options, including drag-and-drop functionality, automatic layout algorithms, zooming, and undo/redo functionality.\\n\\nTo explore these features further and learn how to customize your flowcharts, check out the React Flow documentation and examples.\\n\\nHere\'s a link to learn more about React Flow: [React Flow](https://reactflow.dev/)\\n\\n## Leveraging React Flow in WeDAA\\n\\nAt WeDAA, our platform is dedicated to empowering developers to prototype microservices efficiently. One key component of our platform is the ability to create well-defined architectures seamlessly. To achieve this, we turned to React Flow, a versatile library that enables the creation of interactive node-based user interfaces, such as flowcharts. Let\'s delve into why React Flow became an integral part of our architecture design process and the challenges we encountered along the way.\\n\\nAt the core of WeDAA\'s mission is the desire to provide developers with intuitive tools to design microservice architectures effortlessly. React Flow emerged as the perfect solution due to its ability to facilitate the creation of dynamic, node-based UIs. With React Flow, users can visually construct their architecture diagrams directly within our platform. This interactive approach not only enhances the user experience but also streamlines the process of translating these diagrams into well-defined code structures.\\n\\nBy leveraging React Flow, WeDAA offers users a [visual canvas](https://app.wedaa.tech/canvastocode) where they can intuitively design their architecture using nodes and connectors. This eliminates the need for traditional input forms and empowers users to express their architectural ideas in a more tangible and engaging manner.\\n\\n## Overcoming Challenges with React Flow\\nWhile integrating React Flow into WeDAA presented numerous benefits, it also came with its set of challenges. One significant challenge was ensuring seamless communication between the visual representation of the architecture in React Flow and the backend engine responsible for generating code based on the provided JSON.\\n\\nTo address this challenge, our team worked diligently to establish robust data exchange mechanisms. We developed efficient processes to capture the architecture drawn by users using React Flow and transform it into a structured JSON format. This JSON data is then seamlessly passed to the WeDAA backend engine, where it undergoes further processing to generate the corresponding code.\\n\\n## Empowering Architecture Design with Interactivity\\n\\n### Custom Nodes\\n\\nA powerful feature of React Flow is the ability to add custom nodes. Within your custom nodes you can render everything you want.\\n\\n#### Creating Custom Nodes\\nTo create a custom node, you can leverage the newNode object structure as follows:\\n\\n\\n```jsx\\nconst newNode = {\\n    id: //unique ID you want to provide\\n    type: //type of the node we want to use for this specific node,\\n    position,\\n    data: { label: \\"label you want to display for that specific node\\" },\\n    style: {\\n      //style changes\\n    },\\n};\\n```\\n\\nIn the type field, specify the custom node type you wish to utilize. This approach allows for the creation of nodes with diverse functionalities, enhancing the visual representation of data and interactions.\\n\\n#### Combining Node Functionality\\n\\nReact Flow also supports combining multiple functionalities into a single custom node. For instance, if you want a node to display an image and provide resizing options, you can achieve this by creating a custom node file and incorporating `<NodeResizer>` alongside your content:\\n\\n```jsx\\nreturn (\\n    <>\\n      <NodeResizer\\n        minWidth={60}\\n        minHeight={60}\\n      />\\n      <div>\\n        <img\\n          width=\\"60px\\"\\n          src={image}\\n          alt=\\"img\\"\\n        />\\n      </div>\\n   </>\\n)\\n```\\n\\nThis approach seamlessly integrates diverse features into a cohesive node representation, offering a comprehensive solution for complex UI requirements.\\n\\n#### Example\\n\\nThe image below showcases a custom node used within a React Flow application. This custom node demonstrates the potential for creating visually rich and interactive elements within the flow diagram.\\n\\n![CustomNode Image of React](/img/blog/react-flow/custom-node.png)\\n\\nBy leveraging custom nodes in React Flow, developers can unlock a world of possibilities for creating dynamic and engaging user interfaces.\\n\\n### Adding Handles to All Sides of a Node\\n\\nTo enable edges to connect to any side of a node, serving as both the source and the target, we can add handles to all sides of the node. This functionality enhances the flexibility and interactivity of our flow diagrams.\\n\\n#### Implementation\\n\\nFirst, let\'s add handles to each side (Top, Left, Bottom, Right) of the node:\\n\\n```jsx\\nreturn (\\n  <>\\n    <NodeResizer nodeId={data.id} minWidth={100} minHeight={30} />\\n    <div>{data.label}</div>\\n    <>\\n      <Handle\\n        id=\\"source.Right\\"\\n        position={Position.Right}\\n        type=\\"source\\"\\n        style={sourceStyle}\\n      />\\n      <Handle\\n        id=\\"source.Bottom\\"\\n        position={Position.Bottom}\\n        type=\\"source\\"\\n        style={sourceStyle}\\n      />\\n      <Handle\\n        id=\\"source.Top\\"\\n        position={Position.Top}\\n        type=\\"source\\"\\n        style={sourceStyle}\\n      />\\n      <Handle\\n        id=\\"source.Left\\"\\n        position={Position.Left}\\n        type=\\"source\\"\\n        style={sourceStyle}\\n      />\\n    </>\\n\\n    <Handle position={Position.Left} id=\\"target.Left\\" type=\\"target\\" />\\n    <Handle position={Position.Top} id=\\"target.Top\\" type=\\"target\\" />\\n    <Handle position={Position.Bottom} id=\\"target.Bottom\\" type=\\"target\\" />\\n    <Handle position={Position.Right} id=\\"target.Right\\" type=\\"target\\" />\\n  </>\\n);\\n```\\n\\nNext, let\'s handle the connection logic based on the connectionNodeId in the application\'s state:\\n\\n```jsx\\nconst connectionNodeIdSelector = (state) => state.connectionNodeId;\\n\\nexport default function CustomNode({ id, data, selected }) {\\n  const connectionNodeId = useStore(connectionNodeIdSelector);\\n\\n  const isConnecting = !!connectionNodeId;\\n  const sourceStyle = { zIndex: !isConnecting ? 1 : 0 };\\n\\n  return (\\n\\t\\t\\t// Node component content\\n\\t);\\n}\\n```\\n\\nThe component confidently retrieves the `connectionNodeId` from the application\'s state using the `useStore` hook. It then sets `isConnecting` to `true` if `connectionNodeId` is truthy. Additionally, the `zIndex` of the `sourceStyle` object is set to `1` if `isConnecting` is false, or `0` if `isConnecting` is true.\\n\\nThis approach ensures that whenever a node acts as a source, all the other nodes change their behavior as the target node and vice versa. The desired outcome is achieved through the use of zIndex.\\n\\n#### Example\\n\\nThe image below illustrates a custom node with handles on all sides:\\n\\n![customNode Handles](/img/blog/react-flow/node-handles.png)\\n\\nThis setup enables seamless edge connections from any side of the node, enhancing the versatility and usability of the React Flow diagrams.\\n\\n### Deleting a node or a edge\\n\\nTo enhance node and edge deletion functionality in a React Flow application, React Flow offers a default deletion function triggered by the Backspace key on the keyboard. However, if the requirement is to extend this functionality to include the Delete key as well, the process can be accomplished by utilizing the **`deleteKeyCode`** property and adding the corresponding key codes for the Delete key.\\n\\n```jsx\\n<ReactFlow deleteKeyCode={[\\"Backspace\\", \\"Delete\\"]}></ReactFlow>\\n```\\n\\n### Adding Color Options to Nodes\\n\\nWhile React Flow doesn\'t have a direct method for setting specific background colors for nodes, we can achieve this functionality by defining a function to handle color changes and incorporating color options into our node components.\\n\\n#### Color Change Function\\n\\nLet\'s start by defining the handleColorClick function, which will be responsible for changing the background color of a node:\\n\\n```jsx\\nconst handleColorClick = (color) => {\\n  let UpdatedNodes = { ...nodes };\\n  setSelectedColor(color);\\n  (UpdatedNodes[nodeClick].style ??= {}).backgroundColor = color;\\n  setNodes(UpdatedNodes);\\n};\\n```\\n\\nThis is a code defines a function called `handleColorClick`. The function takes a single argument, `color`, which is a string representing the color to set as the background color of a node.\\n\\nThe function first creates a copy of the `nodes` object using the spread operator, so that the original object is not modified directly. It then sets the `selectedColor` state variable to the provided `color`. Finally, it sets the `backgroundColor` property of the node with the ID specified by `nodeClick` to the provided `color`. If the `style` property does not exist for that node, it will be created and set to an empty object before the `backgroundColor` property is added to it. The nullish coalescing operator (`??=`) ensures that the `style` property is set to an object if it does not already exist.\\n\\n#### Adding Color Options\\n\\nNext, let\'s add color options to our node component and link them to the handleColorClick function:\\n\\n```jsx\\n<div\\n  style={{\\n      width: \\"30px\\",\\n      height: \\"30px\\",\\n      borderRadius: \\"50%\\",\\n      backgroundColor: //desiredColor,\\n      cursor: \\"pointer\\",\\n  }}\\n  onClick={() => handleColorClick()} //desiredColor\\n></div>\\n```\\n\\n#### Example\\n\\nThe animation below demonstrates changing the color of a node:\\n\\n<video controls width=\\"740\\" height=\\"420\\">\\n  <source src=\\"/docs/videos/node-color.mp4\\" type=\\"video/mp4\\"></source>\\n</video>\\n\\nBy implementing color options and the color change function, you can customize the appearance of nodes in your React Flow diagrams to match your design preferences or convey specific information.\\n\\n### Adding Backgroup Grid to Canvas\\n\\nIn React Flow, the ability to add a background grid to the canvas provides a valuable tool for maintaining precise alignment and enhancing the aesthetics of your flowchart. Whether you\'re crafting a complex diagram or a simple layout, the grid system ensures that nodes and elements align perfectly, contributing to a well-organized and visually appealing flow chart.\\n\\n#### Implementation\\n\\nTo add a background grid to your React Flow canvas, you can use the `<Background>` component with specific configurations. Here\'s an example of how to implement it:\\n\\n```jsx\\n<ReactFlow>\\n  <Background\\n    gap={} //desired gap between patterns\\n    color=\\"\\" //desired color for grid\\n    variant=\\"\\" //declaring the type of variant we want to use for grid(line/grid/dots)\\n  />\\n</ReactFlow>\\n```\\n\\nIn this code snippet, we set the gap prop to define the gap between grid patterns, the color prop to specify the color of the grid, and the variant prop to determine the type of grid variant (lines, grid, dots).\\n\\n#### Example\\n\\nThe image below showcases a custom node with a background grid applied to the canvas:\\n\\n![customNode Background](/img/blog/react-flow/background.png)\\n\\nBy incorporating a background grid, you can ensure precise alignment and enhance the overall visual appeal of your flowchart or diagram in React Flow.\\n\\n### Saving Node Positions and Dimensions\\n\\nIn React Flow, the onNodesChange function plays a crucial role in handling changes to nodes within the flow. It\'s often called in response to user actions like dragging nodes, selecting nodes, or removing nodes.\\n\\n#### Implementing onNodesChange\\n\\nFirst, let\'s set up onNodesChange in our React Flow component:\\n\\n```jsx\\n<ReactFlow\\n  onNodesChange={\\n    (changes) => onNodesChange() //desiredArguments, changes\\n  }\\n></ReactFlow>\\n```\\n\\nThe onNodesChange callback receives a list of changes when nodes are modified in the flow. We pass these changes to our onNodesChange function to handle updates.\\n\\n#### Handling Position and Dimension Changes\\n\\nInside onNodesChange, we can handle position and dimension changes using a switch case:\\n\\n```jsx\\nconst onNodesChange = useCallback((/*desiredArguments*/, changes = []) => {\\n  const updatedNodes = { ...nodes };\\n  changes.forEach((change) => {\\n    switch (change.type) {\\n      case \\"dimensions\\":\\n        if (change.resizing) {\\n          updatedNodes[change.id] = {\\n            ...updatedNodes[change.id],\\n            position: {\\n              ...updatedNodes[change.id].position,\\n            },\\n            style: {\\n              ...updatedNodes[change.id].style,\\n              ...change.dimensions,\\n            },\\n          };\\n        }\\n        break;\\n      case \\"position\\":\\n        // Add logic for handling position changes\\n        break;\\n      case \\"select\\":\\n        // Add logic for handling node selection\\n        break;\\n      case \\"remove\\":\\n        // Add logic for handling node removal\\n        break;\\n      // Handle other cases as needed\\n    }\\n  });\\n}, []);\\n```\\n\\nIn this example, we focus on handling dimension changes (change.type === \\"dimensions\\") by updating the node\'s dimensions and style accordingly. You can similarly add logic for position changes (change.type === \\"position\\") or other types of changes as required.\\n\\n#### Example\\n\\nThe animation below demonstrates saving node positions and dimensions after submitting:\\n\\n<video controls width=\\"740\\" height=\\"420\\">\\n  <source src=\\"/docs/videos/node-dimension-change.mp4\\" type=\\"video/mp4\\"></source>\\n</video>\\n\\nBy leveraging onNodesChange and handling different change types effectively, we ensure that node positions and dimensions are updated and saved seamlessly within the React Flow environment.\\n\\n\\n### Handling Edge Changes with onEdgesChange\\n\\nIn addition to managing node changes, React Flow provides the onEdgesChange callback to handle modifications to edges within the flow. This includes actions like adding or removing edges, which are essential for creating a controlled and interactive flow diagram.\\n\\n#### Implementing onEdgesChange\\n\\nLet\'s integrate onEdgesChange into our React Flow component:\\n\\n```jsx\\nconst onEdgesChange = useCallback((nodes, changes = []) => {\\n  changes.forEach((change) => {\\n    switch (change.type) {\\n      case \\"add\\":\\n        // Handle edge addition\\n        break;\\n      case \\"remove\\":\\n        // Handle edge removal\\n        break;\\n      // Add other cases as needed\\n      default:\\n        break;\\n    }\\n  });\\n}, []);\\n```\\n\\nThe onEdgesChange function receives a list of changes when edges are modified in the flow. We can use a switch case to handle different types of changes, such as adding or removing edges.\\n\\n## Conclusion\\n\\nIn conclusion, React Flow has played a pivotal role in revolutionizing architecture design within the WeDAA platform. By empowering users to visually construct their architectures using intuitive node-based interfaces, React Flow has enhanced the efficiency and creativity of our users\' workflow. Despite the challenges encountered along the way, the integration of React Flow has proven to be a valuable asset in achieving our goal of simplifying microservice prototyping.\\n\\n\\nExperience Our Visual canvas built using React Flow: [WeDAA Canvas](https://app.wedaa.tech/canvastocode)"},{"id":"/2024/04/18/feature-flags","metadata":{"permalink":"/docs/blog/2024/04/18/feature-flags","source":"@site/blog/2024-04-18-feature-flags.md","title":"Unveiling the Power of Feature Flags in Software Development","description":"Unveiling the Power of Feature Flags in Software Development","date":"2024-04-18T00:00:00.000Z","formattedDate":"April 18, 2024","tags":[{"label":"featureflags","permalink":"/docs/blog/tags/featureflags"},{"label":"architecture","permalink":"/docs/blog/tags/architecture"},{"label":"bestpractices","permalink":"/docs/blog/tags/bestpractices"},{"label":"flagsmith","permalink":"/docs/blog/tags/flagsmith"},{"label":"go","permalink":"/docs/blog/tags/go"}],"readingTime":3.53,"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"Unveiling the Power of Feature Flags in Software Development","description":"Unveiling the Power of Feature Flags in Software Development","image":"https://www.wedaa.tech/docs/img/blog/feature-flags/banner.jpg","tags":["featureflags","architecture","bestpractices","flagsmith","go"],"date":"2024-04-18T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"Revolutionizing Software Development with React Flow","permalink":"/docs/blog/2024/04/25/react-flow"},"nextItem":{"title":"Microservice architecture using GoMicro","permalink":"/docs/blog/2024/04/17/Go-Micro"}},"content":"## Introduction\\n\\nIn the realm of software development, there is often a need for implementing features dynamically, toggling functionalities, and rolling out changes seamlessly without disrupting user experience. Imagine this scenario: you\'re working on a high-stakes project, and you need to introduce a new feature. However, releasing it to all users at once might be risky. What if there are bugs? What if users don\'t like it? This is where feature flags come to the rescue.\\n\\n### The Tale of Dynamic Feature Rollouts\\n\\nLet\'s delve into a hypothetical scenario. Meet Adam, a software engineer working on a cutting-edge e-commerce platform. Their team is gearing up to introduce a new payment gateway, which promises to enhance user experience and reduces failure rates. However, they\'re wary of unforeseen bugs that might surface during the rollout. Plus, they\'re unsure if the new checkout flow will resonate well with all users.\\n\\nHere\'s where feature flags come into play. By leveraging feature flags, Adam and their team can deploy the new payment gateway to a small subset of users initially. They can monitor its performance, gather feedback, and make necessary tweaks without affecting the entire user base. Once they\'re confident in the feature\'s stability and user acceptance, they can gradually roll it out to all users, mitigating risks and ensuring a smooth transition.\\n\\n### Understanding Feature Flags\\n\\nFeature flags, also known as feature toggles or feature switches, are a powerful technique used in software development to enable or disable certain features at runtime. They provide developers with fine-grained control over feature rollout, allowing them to manage feature releases, perform A/B testing, and mitigate risks associated with deploying new functionalities.\\n\\n## Hands-on\\n\\nIn this blog, we\'ll explore how to implement feature flags using the Flagsmith in a Go application built on the Go-Micro framework.\\n\\n### Generate prototype from WeDAA\\n\\nUse below Architecture as reference and generate code from [WeDAA](https://app.wedaa.tech/canvastocode)\\n\\n![A Go Micro Service](/img/blog/feature-flags/prototype.png)\\n\\n### Setup Flagsmith\\n\\n[Flagsmith](https://www.flagsmith.com) is a feature flag tool that lets you manage features across web, mobile and server side applications.\\n\\nIt provides free account as well for SaaS offering. Signup, Create Organisation and add a feature flag.\\n\\n![Flagsmith setup](/img/blog/feature-flags/flagsmith.png)\\n\\n### Flagsmith SDK\\n\\nInclude flagsmith SDK in **go.mod**\\n\\n```\\ngithub.com/Flagsmith/flagsmith-go-client/v3 v3.4.0\\n```\\n\\n### Payment Handler\\n\\nIn this snippet, we initialize the Flagsmith client with our API key, retrieve the status of a feature flag, and conditionally execute feature-specific functionality based on the flag\'s status.\\n\\n```go\\n// src/handlers/payments.go\\npackage handler\\n\\nimport (\\n\\t\\"context\\"\\n\\t\\"net/http\\"\\n\\tflagsmith \\"github.com/Flagsmith/flagsmith-go-client/v3\\"\\n)\\n\\ntype PaymentsHandler struct{}\\n\\nfunc (handler *PaymentsHandler) ProcessPayment(response http.ResponseWriter, request *http.Request) {\\n\\tclient := flagsmith.NewClient(\\"<YOUR_FLAGSMITH_API_KEY>\\")\\n\\tflags, _ := client.GetEnvironmentFlags(context.TODO())\\n\\tisEnabled, _ := flags.IsFeatureEnabled(\\"payment_gateway\\")\\n\\n\\tif isEnabled {\\n\\t\\tresponse.Write([]byte(`{ \\"message\\": \\"New Payment Gateway\\" }`))\\n\\t} else {\\n\\t\\tresponse.Write([]byte(`{ \\"message\\": \\"Old Payment Gateway\\" }`))\\n\\t}\\n}\\n```\\n\\n### Payment Controller\\n\\nA sample controller with API to simulate payments.\\n\\n```go\\n// src/controllers/payments.go\\npackage controllers\\n\\nimport (\\n   \\"github.com/gorilla/mux\\"\\n   \\"net/http\\"\\n   \\"payments/handlers\\"\\n)\\n\\nvar paymentsHandler *handler.PaymentsHandler\\n\\ntype PaymentsController struct {}\\n\\nfunc (paymentsController PaymentsController) RegisterRoutes(r *mux.Router) {\\n\\tr.Handle(\\"/api/payments\\",http.HandlerFunc(paymentsHandler.ProcessPayment)).Methods(http.MethodGet,http.MethodOptions)\\n}\\n```\\n\\n### Register Payments Controller \\n\\nAdd the following code in registerRoutes function of **main.go** in src\\n\\n```go\\nfunc registerRoutes(router *mux.Router) {\\n    registerControllerRoutes(controllers.ManagementController{}, router)\\n    registerControllerRoutes(controllers.PaymentsController{}, router) // Register Payments Controller\\n}\\n```\\n\\n### Execution\\n\\n1. Run the Go Micro Service using following commands\\n   \\n   ```\\n   go mod tidy\\n   go run .\\n   ```\\n\\n2. Check health of the service\\n   \\n   ```\\n   curl -i -H \\"Accept: application/json\\" http://localhost:6060/management/health/readiness\\n   ```\\n\\n   Response should be as follows\\n   ```\\n   HTTP/1.1 200 OK\\n   Access-Control-Allow-Headers: Origin, Content-Type, Accept,Authorization\\n   Access-Control-Allow-Methods: GET, POST, PUT, DELETE, OPTIONS\\n   Access-Control-Allow-Origin: *\\n   Content-Type: application/json\\n   Date: Wed, 17 Apr 2024 19:30:53 GMT\\n   Content-Length: 64\\n   \\n   {\\"components\\":{\\"readinessState\\":{\\"status\\":\\"UP\\"}},\\"status\\":\\"UP\\"}\\n   ```\\n\\n3. Test the new Payment API\\n\\n   ```\\n   curl -i -H \\"Accept: application/json\\" http://localhost:6060/api/payments\\n   ```\\n\\n   Response will be based on feature flag, whether new or old payment gateway is used.\\n   ```\\n   HTTP/1.1 200 OK\\n   Access-Control-Allow-Headers: Origin, Content-Type, Accept,Authorization\\n   Access-Control-Allow-Methods: GET, POST, PUT, DELETE, OPTIONS\\n   Access-Control-Allow-Origin: *\\n   Content-Type: application/json\\n   Date: Wed, 17 Apr 2024 19:33:33 GMT\\n   Content-Length: 36\\n   \\n   { \\"message\\": \\"New Payment Gateway\\" }\\n   ```\\n\\n## Conclusion\\n\\nFeature flags revolutionize the way software is developed and released. They empower developers to iterate quickly, gather feedback, and deliver value to users with confidence. By adopting feature flags in your development workflow, you can mitigate risks, improve deployment agility, and ultimately, delight your users with timely and impactful features."},{"id":"/2024/04/17/Go-Micro","metadata":{"permalink":"/docs/blog/2024/04/17/Go-Micro","source":"@site/blog/2024-04-17-Go-Micro.md","title":"Microservice architecture using GoMicro","description":"Building Microservices architecture using GoMicro","date":"2024-04-17T00:00:00.000Z","formattedDate":"April 17, 2024","tags":[{"label":"go","permalink":"/docs/blog/tags/go"},{"label":"microservices","permalink":"/docs/blog/tags/microservices"},{"label":"prototyping","permalink":"/docs/blog/tags/prototyping"}],"readingTime":4.81,"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"Microservice architecture using GoMicro","description":"Building Microservices architecture using GoMicro","image":"https://bairesdev.mo.cloudinary.net/blog/2023/08/golang.jpg?tx=w_1920,q_auto","tags":["go","microservices","prototyping"],"date":"2024-04-17T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"Unveiling the Power of Feature Flags in Software Development","permalink":"/docs/blog/2024/04/18/feature-flags"},"nextItem":{"title":"Dive into Knative\u2014Explore Serverless with Kubernetes","permalink":"/docs/blog/2024/04/13/overview-on-knative"}},"content":"In today\'s scenario, we are seeing a shift from the monolithic landscape to microservice landscape. In simple words it can be termed as breaking a complex problem into smaller parts and making it easier to manage and develop. In Go to make this easier there is a framework GO MICRO - a helpful framework for building microservice applications with the Go programming language.\\n\\n### Why Microservice Architecture\\n\\nImagine a library where all the books used to be stacked in one massive room. It would be chaotic trying to find the book you needed among the towering shelves. But now, picture this library transformed into a series of smaller rooms, each dedicated to a specific genre\u2014mystery, romance, science fiction, and so on. Each room is organized neatly, making it easier for readers to find the books they\'re looking for without getting lost in the sea of literature. This is similar to how microservices work in software\u2014they break down complex applications into smaller, specialized components, making it simpler for developers to manage and maintain the software.\\n\\nNow how do we build them??\\n\\n## Meet GOMICRO - A framework for distributed systems development\\n\\nIn the world of microservices, Go Micro is like your trusty sidekick. It helps developers build and manage microservices without all the headaches of doing it from scratch. Think of it as a toolbox full of handy tools to make building microservices easier and faster.\\n\\n### How Go Micro helps us??\\n\\n- **Authentication and Authorization** - Security is paramount in any architecture.Gomicro provide authorization.It seamlessly integrates with authentication providers like Keycloak, serving as a middleware to authenticate incoming requests.\\n\\n- **Service Discovery** - Effective communication among microservices necessitates a reliable service discovery mechanism. Go Micro simplifies this with built-in support for mdns (Multicast DNS) and offers integrable libraries (plugins) for popular options such as Eureka, Etcd, Consul, and NATS, among others.\\n\\n- **Messaging** - Messaging is an important aspect in the microservice architecture and event driven architectures. Go Micro eases the implementation of pub-sub models and other messaging paradigms with its plugin-based approach. Whether it\'s HTTP event message brokering or support for NATS, RabbitMQ, or Kafka, Go Micro has you covered.\\n\\n- **Protocols** - Go Micro supports communication via HTTP and RPC (Remote Procedure Call), providing abstractions for synchronous communication. This flexibility enables developers to choose the most suitable communication protocol for their specific use cases.\\n\\n## Tutorial\\n\\n1. **Visit WeDAA**: Go to [WeDAA](https://app.wedaa.tech/canvastocode).\\n\\n2. **Choose GoMicro Application**: Navigate to the service tab in the sidebar and select Go. Drag and drop it onto the canvas.\\n\\n3. **Connect a Database and Add Authentication**: Connect a database to the application. Additionally, add authentication to secure the  application. WeDAA supports Keycloak as an authentication IDP.\\n\\n![Sample GOMICRO WeDAA Architecture](/img/blog/gomicro/go_micro_one.png)\\n\\n\\n4. **Fill in Required Details**: Provide necessary details for the service and database connection.\\n\\n![Sample GOMICRO WeDAA Architecture](/img/blog/gomicro/go_micro_two.png)\\n\\n\\n5. **Validate and Review**: Click on validate to review the setup. Ensure everything is configured correctly.\\n\\n![Sample GOMICRO WeDAA Architecture](/img/blog/gomicro/go_micro_three.png)\\n\\n\\n6. **Cloud Service Setup (Optional)**: Weeda has support for Azure, AWS and minikube.We can opt for one and fill in the necessary details to deploy applications in the specific cloud provider.we can skip this step for now by selecting none.\\n\\n![Sample GOMICRO WeDAA Architecture](/img/blog/gomicro/go_micro_four.png)\\n\\n\\n7. **Generate Project Zip**: After submission, a zip file containing the project will be generated.\\n\\n### Application Quickstart Guide\\n\\n1. **Prerequisites**: Ensure Docker is set up in advance if Keycloak is not configured as standalone or if PostgreSQL is not set up separately. Keycloak and PostgreSQL provided are Dockerized containers.\\n\\n2. **Start Keycloak and PostgreSQL**:\\n```\\n   docker compose -f docker/keycloak.yml up -d\\n   docker compose -f docker/postgresql.yml up -d\\n```\\n\\n3. **Start the Go Service**: Once Keycloak and PostgreSQL services are up, start the Go service.\\n\\n4. **Install Dependencies and Run the Service**:\\n```\\n   go mod tidy\\n   go run .\\n```\\nThis command will install any required dependencies and then run the Go service.\\n\\n### Understanding the code\\n\\n```go\\npackage main\\n\\nfunc main() {\\n\\tapp.Setconfig()\\n\\tmigrate.MigrateAndCreateDatabase()\\n\\tauth.SetClient()\\n\\tconfig.InitializeDb()\\n\\tport :=app.GetVal(\\"GO_MICRO_SERVICE_PORT\\")\\n\\tsrv := micro.NewService(\\n\\t\\tmicro.Server(mhttp.NewServer()),\\n    )\\n\\topts1 := []micro.Option{\\n\\t\\tmicro.Name(\\"backendone\\"),\\n\\t\\tmicro.Version(\\"latest\\"),\\n\\t\\tmicro.Address(\\":\\"+port),\\n\\t}\\n\\tsrv.Init(opts1...)\\n\\tr := mux.NewRouter().StrictSlash(true)\\n\\tr.Use(corsMiddleware)\\n\\tregisterRoutes(r)\\t\\t\\n\\tvar handlers http.Handler = r\\n\\t\\n    if err := micro.RegisterHandler(srv.Server(), handlers); err != nil {\\n\\t\\tlogger.Fatal(err)\\n\\t}\\n\\t\\n\\tif err := srv.Run(); err != nil {\\n\\t\\tlogger.Fatal(err)\\n\\t}\\n}\\n```\\n\\n- **Config Initialization** - The application begins by loading configuration values from externalized YAML files into the environment. This ensures that the application has access to the necessary configuration parameters.\\n\\n- **Database Migration** - WeDAA supports migration for PostgreSQL databases. Using the go-migrate package library, a new database is created and data initialization is performed. This ensures that the database is properly set up and populated with initial data.\\n\\n- **Authentication Setup** - The code proceeds by setting up the authentication client,here Keycloak is being used as the identity provider (IDP) for authentication. This involves establishing a connection to Keycloak.\\n\\n- **Microservice Setup** - The micro.NewService function is a notation used by GoMicro to set up the microservice. Here, configurations are provided to the microservice via options. This step initializes the microservice and prepares it to handle incoming requests.\\n\\n- **Router Setup** - The code utilizes the mux router to create a routing setup. This involves defining endpoints and their corresponding handlers. The router is then registered with GoMicro, indicating that the microservice should use this router to handle incoming requests.\\n\\n- **Application Execution** - Finally, the application is run. This step starts the microservice, allowing it to listen for incoming requests and handle them according to the defined routing setup.\\n\\n## Conclusion\\n\\nGo Micro leverages Go interfaces for each distributed system abstraction, rendering them pluggable and runtime-agnostic. This inherent flexibility allows developers to seamlessly integrate various underlying technologies, optimizing microservice development in a clean and efficient manner."},{"id":"/2024/04/13/overview-on-knative","metadata":{"permalink":"/docs/blog/2024/04/13/overview-on-knative","source":"@site/blog/2024-04-13-overview-on-knative.md","title":"Dive into Knative\u2014Explore Serverless with Kubernetes","description":"Overview on Knative","date":"2024-04-13T00:00:00.000Z","formattedDate":"April 13, 2024","tags":[{"label":"microservices","permalink":"/docs/blog/tags/microservices"},{"label":"architecture","permalink":"/docs/blog/tags/architecture"},{"label":"cloud-native","permalink":"/docs/blog/tags/cloud-native"},{"label":"Serverless","permalink":"/docs/blog/tags/serverless"},{"label":"cloud computing","permalink":"/docs/blog/tags/cloud-computing"},{"label":"knative","permalink":"/docs/blog/tags/knative"},{"label":"kubernetes","permalink":"/docs/blog/tags/kubernetes"}],"readingTime":7.9,"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"Dive into Knative\u2014Explore Serverless with Kubernetes","description":"Overview on Knative","image":"https://dzrge5zzbsh6q.cloudfront.net/Enterprise-Software-Development-with-Knative-1024x614.jpg.webp","tags":["microservices","architecture","cloud-native","Serverless","cloud computing","knative","kubernetes"],"date":"2024-04-13T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"Microservice architecture using GoMicro","permalink":"/docs/blog/2024/04/17/Go-Micro"},"nextItem":{"title":"Rapid Application Prototyping (RAP)","permalink":"/docs/blog/2024/04/08/rapid-application-prototyping"}},"content":"## What is serverless?\\nServerless is a cloud-native development model that allows developers to build and run applications without having to manage servers.\\n\\nThere are still servers in serverless, but they are abstracted away from app development. A cloud provider handles the routine work of provisioning, maintaining, and scaling the server infrastructure. Developers can simply package their code in containers for deployment.\\n\\nOnce deployed, serverless apps respond to demand and automatically scale up and down as needed.\\n\\n### Serverless Computing: A Catering Service Analogy\\n![Catering Service Analogy](/img/blog/dive-into-knative/01-catering-service-analogy.png)<p align=\\"center\\">[Catering Service Analogy](https://www.freepik.com/premium-vector/catering-concept-illustration-idea-food-service-hotel-event-restaurant-banquet-party-catering-service-web-banner-illustration_10275389.htm)</p>\\n\\nImagine you\'re hosting a dinner party. In a traditional hosting scenario, you\'d have to plan everything from cooking the food to setting the table and serving your guests. This is like managing servers in traditional computing \u2013 you have to handle all the details yourself.\\n\\nNow, consider a serverless approach as hiring a catering service for your party. You tell them what you need, and they take care of everything \u2013 from cooking the food to setting up and serving. You don\'t have to worry about the kitchen logistics or cleaning up afterward; you can focus on enjoying the party with your guests. Similarly, in serverless computing, you provide your code, and the cloud provider takes care of the infrastructure, scaling, and management, allowing you to focus on writing and improving your application.\\n\\n### Kubernetes-Powered Serverless: Introducing Knative\\n![Serverless Framework Knative](/img/blog/dive-into-knative/02-serverless-framework-knative.png)<p align=\\"center\\">[Serverless Framework Knative](https://www.serverless.com/blog/serverless-framework-knative-component)</p>\\n\\n\\n\\nIn the rapidly evolving landscape of cloud computing, serverless technology has become increasingly popular for its simplicity in deploying applications without worrying about infrastructure. Knative, built on top of Kubernetes (k8s), extends the power of Kubernetes to manage serverless workloads seamlessly. While major cloud providers like AWS, Google Cloud, and Microsoft Azure offer their serverless solutions, Knative stands out as an open-source, platform-agnostic framework.\\n\\nCollaboratively developed by industry leaders like Google and Red Hat, Knative abstracts away the complexities of deploying, scaling, and managing containerized applications, allowing developers to focus solely on writing code without worrying about infrastructure management. Knative simplifies serverless deployments across diverse cloud environments, revolutionizing the way applications are developed and deployed in modern cloud-native architectures.\\n\\n### Exploring Knative Features: Simplifying Serverless Deployment\\n\\nServerless refers to running back-end programs and processes in the cloud. Serverless works on an as-used basis, meaning that companies only use what they pay for. Knative is a platform-agnostic solution for running serverless deployments.\\n\\n![Knative Features](/img/blog/dive-into-knative/03-knative-features.png)\\n\\n\\n- **Simpler Abstractions**: simplifies the YAML configuration process by providing custom CRDs (Custom Resource Definitions), \\n                            streamlining the abstraction layers and making development workflows more straightforward.\\n\\n- **Autoscaling**: autoscaling feature seamlessly adjusts resource allocation, scaling applications down to zero and up from zero based on demand.\\n\\n- **Progressive Rollouts**: Customize your rollout strategy with Knative\'s Progressive Rollouts feature, offering flexibility to select the ideal \\n                            approach based on your specific requirements.\\n\\n- **Event Integrations**: Easily manage events from diverse sources with Knative\'s Event Integrations, streamlining event handling for seamless integration.\\n\\n- **Handle Events**: Effortlessly trigger handlers from the event broker with Knative\'s event handling capabilities, ensuring seamless integration \\n                    and streamlined workflow.\\n\\n- **Plugable**: Knative\'s pluggable architecture ensures seamless integration and extension within the Kubernetes ecosystem, providing \\n                flexibility and scalability for diverse use cases.\\n\\n## Knative Components\\n\\nKnative has two main components that empower teams working with Kubernetes. Serving and\\nEventing work together to automate and manage tasks and applications.\\n\\n![Serving Eventing](/img/blog/dive-into-knative/04-serving-eventing.png)\\n\\n- **Knative Serving**: Allows running serverless containers in Kubernetes with ease. Knative takes care of the details of networking, \\n                       autoscaling (even to zero), and revision tracking. Teams can focus on core logic using any programming language.\\n- **Knative Eventing**: Allows universal subscription, delivery and management of events. Build modern apps by attaching compute to a \\n                        data stream with declarative event connectivity and developer friendly object models.\\n\\n### Knative Serving\\n\\nKnative Serving defines a set of objects as Kubernetes Custom Resource Definitions (CRDs). These objects get used to define and control how your serverless workload behaves on the cluster:\\n\\n![Knative Serving](/img/blog/dive-into-knative/05-knative-serving.png)<p align=\\"center\\">Savita Ashture, [CC BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/)</p>\\n\\n\\n- **Service**: A Knative Service describes a combination of a route and a configuration as shown above. It is a higher-level entity that does not provide any additional functionality. It should make it easier to deploy an application quickly and make it available. You can define the service to always route traffic to the latest revision or a pinned revision.\\n\\n- **Route**: The Route describes how a particular application gets called and how the traffic gets distributed across the different revisions. There is a high chance that several revisions can be active in the system at any given time based on the use case in those scenarios. It\'s the responsibility of routes to split the traffic and assign to revisions.\\n\\n- **Configuration**: The Configuration describes what the corresponding deployment of the application should look like. It provides a clean separation between code and configuration and follows the Twelve-Factor App methodology. Modifying a configuration creates a new revision.\\n\\n- **Revision**: The Revision represents the state of a configuration at a specific point in time. A revision, therefore, gets created from the configuration. Revisions are immutable objects, and you can retain them for as long as useful. Several revisions per configuration may be active at any given time, and you can automatically scale up and down according to incoming traffic.\\n\\n#### Knative Serving focuses on:\\n- Rapid deployment of serverless containers.\\n- Autoscaling includes scaling pods down to zero.\\n- Support for multiple networking layers such as Ambassador, Contour, Kourier, Gloo, and Istio for integration into existing environments.\\n- Give point-in-time snapshots of deployed code and configurations.\\n\\n### Knative Eventing\\n\\nKnative Eventing is a collection of APIs that enable you to use an event-driven architecture with your applications. You can create components that route events from event producers to event consumers, known as sinks, that receive events.\\n\\n#### Use-cases\\nGeneral areas of application are:\\n\\n- Publishing an event without creating a consumer. You can send events to a broker as an HTTP POST, and use binding to decouple the destination configuration from your application that produces events.\\n\\n- Consuming an event without creating a publisher. You can use a trigger to consume events from a broker based on event attributes.\\n\\n- IoT, network monitoring, application monitoring, website testing and validation, and mobile app front-end processes that act as event generators.\\n\\n#### Use Knative eventing when:\\n\\n- When you want to publish an event without creating a consumer. You can send events to a broker as an HTTP POST, and use binding to decouple the destination configuration from your application that produces events.\\n\\n- When you want to consume an event without creating a publisher. You can use a trigger to consume events from a broker based on event attributes. The application receives events as an HTTP POST.\\n\\n- When you want to create components that route events from event producers to event consumers, known as sinks, that receive events. Sinks can also be configured to respond to HTTP requests by sending a response event.\\n\\n![Knative Eventing](/img/blog/dive-into-knative/06-knative-eventing.png)<p align=\\"center\\">[Eventing Components](https://dev.to/ashokan/knative-eventing-e95)</p>\\n\\n#### Components\\n\\n- **Sources**: Knative eventing sources are objects that generate events and send them to a sink. They are created by instantiating a custom resource (CR) from a source object. There are different types of sources, such as PingSource, ApiServerSource, KafkaSource, etc., depending on the event producer.\\n\\n- **Sinks**: Knative eventing sinks are objects that receive events from sources or other components. They can be Addressable or Callable resources that have an address defined in their status.address.url field. Addressable sinks can receive and acknowledge an event delivered over HTTP, while Callable sinks can also respond to HTTP requests by sending a response event. Knative Services, Channels, and Brokers are all examples of sinks.\\n\\n- **Brokers**: Knative eventing brokers are objects that define an event mesh for collecting a pool of events. Brokers provide a discoverable endpoint for event ingress, and use triggers for event delivery. Event producers can send events to a broker by posting the event.\\n\\n- **Channels**: Channels are custom resources that define a single event-forwarding and persistence layer. You can connect channels to various backends for sourcing events, such as In-Memory, Kafka, or GCP PubSub. You can also fan-out received events, through subscriptions, to multiple destinations, or sinks. Examples of sinks include brokers and Knative services.\\n\\n- **Subscriptions**: Knative subscriptions are objects that enable event delivery from a channel to an event sink, also known as a subscriber. A subscription specifies the channel and the sink to deliver events to, as well as some sink-specific options, such as how to handle failures.\\n\\n- **Triggers**: Knative Triggers are objects that enable seamless integration with external event sources, allowing applications to react dynamically to incoming events, fostering the development of scalable, event-driven architectures.\\n\\n## Conclusion\\n\\n\\nIn this overview, we\'ve explored serverless computing with Knative on Kubernetes, covering core concepts, features, and components. Stay tuned for practical implementations and real-world use cases in upcoming blogs, unlocking Knative\'s full potential for your projects. With Knative, the future of serverless on Kubernetes is brighter than ever.\\n\\nFurthermore, I\'m excited to announce that our platform, [WeDAA](https://app.wedaa.tech/), will be hosting these upcoming blogs. WeDAA is committed to providing innovative solutions, and soon, we\'ll be incorporating serverless capabilities into our platform. Keep an eye out for our future updates, as we continue to evolve and enhance our services to meet your needs.\\n\\nContinue your exploration of Knative by diving into our next blog on Knative Serving [Definitive Guide to Knative Serving\u2014A Deep Dive into Theory and Architecture](https://www.wedaa.tech/docs/blog/2024/05/01/knative-serving-01)!"},{"id":"/2024/04/08/rapid-application-prototyping","metadata":{"permalink":"/docs/blog/2024/04/08/rapid-application-prototyping","source":"@site/blog/2024-04-08-rapid-application-prototyping.md","title":"Rapid Application Prototyping (RAP)","description":"Rapid Application Prototyping (RAP)","date":"2024-04-08T00:00:00.000Z","formattedDate":"April 8, 2024","tags":[{"label":"prototyping","permalink":"/docs/blog/tags/prototyping"},{"label":"architecture","permalink":"/docs/blog/tags/architecture"},{"label":"bestpractices","permalink":"/docs/blog/tags/bestpractices"}],"readingTime":1.61,"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"Rapid Application Prototyping (RAP)","description":"Rapid Application Prototyping (RAP)","image":"https://www.wedaa.tech/docs/img/blog/rap/banner.png","tags":["prototyping","architecture","bestpractices"],"date":"2024-04-08T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"Dive into Knative\u2014Explore Serverless with Kubernetes","permalink":"/docs/blog/2024/04/13/overview-on-knative"},"nextItem":{"title":"Building event driven microservices architecture with RabbitMQ","permalink":"/docs/blog/2024/01/15/rabbitmq"}},"content":"With the long history of software development, one debate persists: should we prioritize solid application architecture and adhere to best development practices before building a working prototype, or should we quickly create a functional prototype to validate the idea before investing considerable time and resources in identifying technology and architecture?\\n\\nGiven the rapid evolution of technologies and the increasing demands of business requirements, right approach is to emphasises speed while ensuring the quality and robustness of the application or architecture.\\n\\nRapid Application Prototyping (RAP) offers a valuable method to put ideas into action and comprehend both the technical and functional aspects of a solution. Rapid Application Prototyping (RAP) is an approach that prioritizes building and displaying the minimum viable functional view of an application as soon as possible.\\n\\nFew essential aspects of platforms supporting Rapid Application Prototypes.\\n\\n**Modularity**: A prototype should be developed using modern modular architecture patterns, enabling easy integration or modification of business features and technical solutions. Modularity facilitates the construction and maintenance of smaller, more manageable components.\\n\\n![Modularity](/img/blog/rap/modularity.png)\\n\\n**Loose Coupling**: Modular components of the application should possess well-defined interfaces to encourage loose coupling among them. Loose coupling simplifies the integration of new features or technologies.\\n\\n![Loose Coupling](/img/blog/rap/loose-coupling.png)\\n\\n**Scalability**: A RAP platform should support the construction of a scalable architecture, enabling preliminary horizontal scaling of modular components. Scalability is crucial for creating resilient and high-performance systems.\\n\\n![Scalability](/img/blog/rap/scalability.png)\\n\\n**Resilience and Robustness**: In the event of a component failure or issue, the entire system should not necessarily collapse. Failures should be contained within the affected module or service, minimizing their impact on other parts of the application. The modules or services within an application should demonstrate robustness, meaning they can gracefully handle failures, unexpected conditions, and varying loads while maintaining overall functionality and availability.\\n\\n![Resilience and Robustness](/img/blog/rap/resilience.png)\\n\\n[WeDAA](https://app.wedaa.tech) engineering platform empower developers to build Rapid Application Prototypes (RAP) quickly with all the essential features required for building a well architected enterprise application."},{"id":"/2024/01/15/rabbitmq","metadata":{"permalink":"/docs/blog/2024/01/15/rabbitmq","source":"@site/blog/2024-01-15-rabbitmq.md","title":"Building event driven microservices architecture with RabbitMQ","description":"Building event driven microservices architecture with RabbitMQ","date":"2024-01-15T00:00:00.000Z","formattedDate":"January 15, 2024","tags":[{"label":"microservices","permalink":"/docs/blog/tags/microservices"},{"label":"messagebrokers","permalink":"/docs/blog/tags/messagebrokers"},{"label":"rabbitmq","permalink":"/docs/blog/tags/rabbitmq"},{"label":"eventdriven","permalink":"/docs/blog/tags/eventdriven"},{"label":"architecture","permalink":"/docs/blog/tags/architecture"}],"readingTime":4.745,"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"Building event driven microservices architecture with RabbitMQ","description":"Building event driven microservices architecture with RabbitMQ","image":"https://www.wedaa.tech/docs/img/blog/rabbitmq/rabbitmq.png","tags":["microservices","messagebrokers","rabbitmq","eventdriven","architecture"],"date":"2024-01-15T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"Rapid Application Prototyping (RAP)","permalink":"/docs/blog/2024/04/08/rapid-application-prototyping"},"nextItem":{"title":"Securing React applications with Keycloak","permalink":"/docs/blog/2023/12/26/Intergating-keycloak-with-react-app"}},"content":"## The Story\\n\\n![Sample Message Broker App](/img/blog/rabbitmq/message-brokers-app.png)\\n\\nImagine we\'re building a simple e-commerce application. When a customer places an order, it\'s not instantly whisked away by elves. Instead, the order details \u2013 a message filled with product information, shipping address, and payment details \u2013 gets sent to a queue managed by a message broker.\\n\\nMeanwhile, our order processing system sits like a hungry rabbit, constantly checking the queue for new messages. Once it grabs an order message, it springs into action: verifying payment, notifying the warehouse, and sending updates to the customer. All without the two systems ever needing to directly talk to each other!\\n\\nThis decoupling is the superpower of message brokers. Applications don\'t need to know the specifics of each other\'s internal workings. They simply send and receive messages, leaving the orchestration to the broker. This makes systems more flexible, scalable, and resilient.\\n\\nLet\'s delve deeper into this rabbit hole, using RabbitMQ as our trusty guide.\\n\\n## The Technology\\n\\nRabbitMQ is a popular open-source message broker, and it\'s a great starting point to understand the magic behind these event-driven systems.\\n\\n- It is used worldwide at small startups and large enterprises.\\n- It is lightweight and easy to deploy on premises and in the cloud.\\n- It can be deployed in distributed and federated configurations to meet high-scale, high-availability requirements.\\n- It runs on many operating systems and cloud environments, and provides a wide range of developer tools for most popular languages.\\n\\n### The Concepts\\n\\n![RabbitMQ Concepts](https://www.rabbitmq.com/img/tutorials/python-three.png)\\n\\n- Message: It is the fundamental unit of communication in RabbitMQ. It contains the data being sent from the producer to the consumer. It is like a post carrying a message.\\n- Producer: A producer is an application or component that sends messages to RabbitMQ. It is like a person sending the post.\\n- Consumer: A consumer is an application or component that receives and processes messages from RabbitMQ. It is a person receiving the post.\\n- Queue: A queue is a buffer that stores messages until they are consumed. Messages are placed in queues by producers and retrieved by consumers. It is a postbox that stores messages of a person.\\n- Exchange: An exchange is a routing mechanism that receives messages from producers and routes them to queues. It is like a post office.\\n- Routing Key: A routing key is a property of a message that is used by exchanges to determine which queues should receive the message. This is like a mailing address for a post.\\n\\n## The Tutorial\\n\\n### Generate prototype from WeDAA\\n\\nUse below Architecture as reference and generate a project from [WeDAA](https://app.wedaa.tech/canvastocode)\\n\\nAll the code mentioned in the blog will be generated by WeDAA. It can be further extended as necessary.\\n\\n![Sample RabbitMQ WeDAA Architecture](/img/blog/rabbitmq/rabbitmq-demo-arch.png)\\n\\n### RabbitMQ Configuration\\n\\n**RabbitMQConfigOrdersToInventory** class in orders service registers Queue, Exchange, Binding and Message Converters are as beans for auto-configuration in Spring AMPQ.\\n\\n```java\\n@Configuration\\npublic class RabbitMQConfigOrdersToInventory {\\n\\n    public static final String QUEUE = \\"OrdersToInventory_message_queue\\";\\n    public static final String EXCHANGE = \\"OrdersToInventory_message_exchange\\";\\n    public static final String ROUTING_KEY = \\"OrdersToInventory_message_routingKey\\";\\n\\n    @Bean\\n    public Queue queueOrdersToInventory() {\\n        return new Queue(QUEUE);\\n    }\\n\\n    @Bean\\n    public TopicExchange exchangeOrdersToInventory() {\\n        return new TopicExchange(EXCHANGE);\\n    }\\n\\n    @Bean\\n    public Binding bindingOrdersToInventory() {\\n        return BindingBuilder.bind(this.queueOrdersToInventory()).to(this.exchangeOrdersToInventory()).with(ROUTING_KEY);\\n    }\\n\\n    @Bean\\n    public MessageConverter messageConverter() {\\n        return new Jackson2JsonMessageConverter();\\n    }\\n\\n    @Bean\\n    public AmqpTemplate template(ConnectionFactory connectionFactory) {\\n        RabbitTemplate template = new RabbitTemplate(connectionFactory);\\n        template.setMessageConverter(messageConverter());\\n        return template;\\n    }\\n}\\n```\\n\\n### Message Producer\\n\\n**RabbitMQProducerOrdersToInventory** class in orders service sends a message to the exchange every 15 seconds.\\n\\n```java\\n@Scheduled(cron = \\"0/15 * * * * *\\")\\npublic void publishMessage() {\\n    RabbitMessageModel message = new RabbitMessageModel();\\n    message.setMessage(\\"Publishing this message from orders with key: \\" + RabbitMQConfigOrdersToInventory.QUEUE);\\n    message.setDateTime(new Date());\\n    template.convertAndSend(RabbitMQConfigOrdersToInventory.EXCHANGE, RabbitMQConfigOrdersToInventory.ROUTING_KEY, message);\\n    logger.info(\\"Message Published Successfully\\");\\n}\\n```\\n\\n### Message Consumer\\n\\n**RabbitMQConsumerOrdersToInventory** in the inventory service starts receiving the messages as the messages are sent by the Producer.\\n\\n```go\\nmsgs, err := channel.Consume(\\n    queueName,\\n    \\"\\",\\n    true,\\n    false,\\n    false,\\n    false,\\n    nil,\\n)\\n\\nforever := make(chan bool)\\ngo func() {\\n    for d := range msgs {\\n        logger.Infof(\\"Received Message: %s\\\\n\\", d.Body)\\n    }\\n}()\\n<-forever\\n```\\n\\n### The execution\\n\\n1. Bootup the RabbitMQ server\\n   \\n   WeDAA provides dockerfile for starting RabbitMQ server quickly.\\n   It can be found in both inventory and orders service.\\n\\n   RabbitMQ server can be started using below command from orders service.\\n\\n   ```\\n   docker compose -f src/main/docker/rabbitmq.yml up --wait\\n   ```\\n\\n   RabbitMQ\'s management console can be accessed on http://localhost:15672/\\n\\n   Default username: *guest*, password: *guest*\\n\\n2. Start the orders service\\n   \\n   In the sample architecture, orders service acts as producer.\\n   Start the service using the following command\\n   ```\\n   ./mvnw\\n   ```\\n   Once the service is started, it can be seen from the logs that messages are sent periodically.\\n   ```\\n    2024-01-15T20:35:00.015+05:30  INFO 55955 --- [rs-scheduling-1] .o.c.r.RabbitMQProducerOrdersToInventory : Message Published Successfully \\n    2024-01-15T20:35:15.008+05:30  INFO 55955 --- [rs-scheduling-1] .o.c.r.RabbitMQProducerOrdersToInventory : Message Published Successfully \\n    2024-01-15T20:35:30.003+05:30  INFO 55955 --- [rs-scheduling-1] .o.c.r.RabbitMQProducerOrdersToInventory : Message Published Successfully \\n    2024-01-15T20:35:45.002+05:30  INFO 55955 --- [rs-scheduling-1] .o.c.r.RabbitMQProducerOrdersToInventory : Message Published Successfully \\n   ```\\n\\n3. Start the inventory service\\n\\n   In the sample architecture, inventory service acts as consumer.\\n\\n   Build and start the service using the following commands\\n   ```\\n   go mod tidy\\n   go run .\\n   ```\\n   Once started, inventory service starts consuming the messages sent by orders service.\\n\\n   ```\\n    2024-01-15 20:41:33  file=rabbitmq/RabbitMQConsumerOrdersToInventory.go:51 level=info Received Message: {\\"id\\":1,\\"message\\":\\"Publishing this message from orders with key: OrdersToInventory_message_queue\\",\\"dateTime\\":1705331085013}\\n    2024-01-15 20:41:33  file=rabbitmq/RabbitMQConsumerOrdersToInventory.go:51 level=info Received Message: {\\"id\\":2,\\"message\\":\\"Publishing this message from orders with key: OrdersToInventory_message_queue\\",\\"dateTime\\":1705331100012}\\n    2024-01-15 20:41:33  file=rabbitmq/RabbitMQConsumerOrdersToInventory.go:51 level=info Received Message: {\\"id\\":3,\\"message\\":\\"Publishing this message from orders with key: OrdersToInventory_message_queue\\",\\"dateTime\\":1705331115005}\\n    2024-01-15 20:41:33  file=rabbitmq/RabbitMQConsumerOrdersToInventory.go:51 level=info Received Message: {\\"id\\":4,\\"message\\":\\"Publishing this message from orders with key: OrdersToInventory_message_queue\\",\\"dateTime\\":1705331130001}\\n   ```\\n\\n4. Track activity on RabbitMQ management console\\n\\n![RabbitMQ Exchange](/img/blog/rabbitmq/exchange.png)\\n\\n![RabbitMQ Queue](/img/blog/rabbitmq/queue.png)\\n\\n## The Conclusion\\n\\nThis blog gives a head start on making use of RabbitMQ to orchestrate your event-driven microservice application architectures.\\n\\nLearn more from: https://www.rabbitmq.com/getstarted.html"},{"id":"/2023/12/26/Intergating-keycloak-with-react-app","metadata":{"permalink":"/docs/blog/2023/12/26/Intergating-keycloak-with-react-app","source":"@site/blog/2023-12-26-Intergating-keycloak-with-react-app.md","title":"Securing React applications with Keycloak","description":"Intergating Keycloak with React app with \\"react-oidc-context\\"","date":"2023-12-26T00:00:00.000Z","formattedDate":"December 26, 2023","tags":[{"label":"keycloak","permalink":"/docs/blog/tags/keycloak"},{"label":"react","permalink":"/docs/blog/tags/react"},{"label":"authentication","permalink":"/docs/blog/tags/authentication"},{"label":"prototyping","permalink":"/docs/blog/tags/prototyping"},{"label":"boilerplate","permalink":"/docs/blog/tags/boilerplate"}],"readingTime":5.52,"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"Securing React applications with Keycloak","description":"Intergating Keycloak with React app with \\"react-oidc-context\\"","image":"https://i.imgur.com/jtapJ0a.png","tags":["keycloak","react","authentication","prototyping","boilerplate"],"date":"2023-12-26T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"Building event driven microservices architecture with RabbitMQ","permalink":"/docs/blog/2024/01/15/rabbitmq"},"nextItem":{"title":"Transitioning from Boilerplate Development to Scaffolding Frameworks","permalink":"/docs/blog/2023/11/11/boilerplate-to-scaffolding"}},"content":"In the fast-paced world of web development, prioritizing the security of our applications is paramount. This blog post takes you on a journey to enhance the security of your React app by seamlessly integrating it with [**Keycloak**](https://www.keycloak.org/documentation), a robust authentication and authorization server. To simplify this process, we\'ll leverage the npm package [**react-oidc-context**](https://www.npmjs.com/package/react-oidc-context), bridging React and Keycloak while implementing OpenID Connect (OIDC). Whether you\'re a seasoned developer or just stepping into React and authentication, this post provides practical insights to bolster the security posture of your web application. Let\'s dive into the world of React, Keycloak, and react-oidc-context for a more secure development experience.\\n\\n### \ud83d\ude80 Quickstart:\\n\\n1. Visit [**app.wedaa.tech**](https://app.wedaa.tech/)\\n\\n2. Click on the \\"Static Web page\\" component\\n\\n   ![Choose Framework](https://i.imgur.com/aCPQE39.png)\\n\\n3. Select a frontend framework: React, then click next\\n\\n   ![Choose React](https://i.imgur.com/ROlem4b.png)\\n\\n4. Choose Authentication and Authorization: Keycloak, then click Next \\n\\n   ![Choose Keycloak](https://i.imgur.com/3dX4Ttc.png)\\n\\n5. Review your project composition and confirm by clicking \\"Go to Canvas\\"\\n\\n   ![Review Composition](https://i.imgur.com/KNTDOUt.png)\\n\\n6. Provide a valid name to your prototype and click on \\"Validate\\"\\n\\n   ![Prototype Validation](https://i.imgur.com/FVw7YEp.png)\\n\\n7. Review your prototype configuration, then click Next\\n\\n   ![Prototype Configuration](https://i.imgur.com/NYlY6pF.png)\\n\\n8. Finally, click \\"Generate Code\\" to download the secured React application\\n\\n   ![Generate Code](https://i.imgur.com/kJiRTHB.png)\\n\\n\\n\\nWeDAA offers a pre-configured React application secured by Keycloak. Simply extract our application, follow the instructions in the README, and initiate your application to seamlessly experience it first-hand.\\n\\n### \ud83e\udde0 Understanding the Generated Code \\n\\n1. src/index.js\\n\\n```jsx\\n// Code for initializing React application with authentication and authorization capabilities.\\nimport React from \'react\';\\nimport ReactDOM from \'react-dom/client\';\\nimport \'./index.css\';\\nimport App from \'./App\';\\nimport reportWebVitals from \'./reportWebVitals\';\\nimport { AuthProvider } from \'react-oidc-context\';\\n\\nconst oidcConfig = {\\n  authority: process.env.REACT_APP_OIDC_AUTHORITY,\\n  client_id: process.env.REACT_APP_OIDC_CLIENT_ID,\\n  redirect_uri: process.env.REACT_APP_PROJECT_URL,\\n  // ...\\n};\\n\\nconst root = ReactDOM.createRoot(document.getElementById(\'root\'));\\nroot.render(\\n  <AuthProvider {...oidcConfig}>\\n    <App />\\n  </AuthProvider>\\n);\\n\\n// If you want to start measuring performance in your app, pass a function\\n// to log results (for example: reportWebVitals(console.log))\\n// or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals\\nreportWebVitals();\\n\\n```\\n\\n- This code initializes a React application with authentication and authorization capabilities using the [**react-oidc-context**](https://www.npmjs.com/package/react-oidc-context) library.\\n\\n- The main application (App) is wrapped in an AuthProvider with configurations derived from the OIDC parameters specified in the oidcConfig object.\\n\\n- The oidcConfig object contains configuration parameters required for OpenID Connect authentication.\\n\\n- Environment variables (```REACT_APP_OIDC_AUTHORITY, REACT_APP_OIDC_CLIENT_ID, and REACT_APP_PROJECT_URL```) are used to dynamically set these values.\\n\\n2. dotenv (.env file)\\n\\n```jsx\\n// Environment variables for configuring the React application.\\nPORT=4200\\nGENERATE_SOURCEMAP=false\\n\\nREACT_APP_PROJECT_NAME=webapp\\nREACT_APP_PROJECT_URL=http://localhost:4200\\n\\n\\n# WEDAA \\nREACT_APP_WEDAA_DOCS=https://wedaa-tech.github.io\\nREACT_APP_WEDAA_GITHUB=https://github.com/wedaa-tech\\n\\n# OIDC Configuration\\nREACT_APP_OIDC_AUTHORITY=http://localhost:9080/realms/jhipster\\nREACT_APP_OIDC_CLIENT_ID=web_app\\n\\n```\\n\\n3. src/config/auth/privateRoute.js\\n\\n```jsx\\n// Code for defining a PrivateRoute component for protecting routes based on authentication status.\\nimport React from \'react\';\\nimport { useAuth } from \'react-oidc-context\';\\n\\nconst PrivateRoute = ({ children }) => {\\n  const auth = useAuth();\\n\\n  switch (auth.activeNavigator) {\\n    case \'signinSilent\':\\n      return <div>Signing you in...</div>;\\n    case \'signoutRedirect\':\\n      return <div>Signing you out...</div>;\\n  }\\n\\n  if (auth.isLoading) {\\n    // <div>Loading...</div>;\\n    return <div></div>;\\n  }\\n\\n  if (auth.error) {\\n    return <div>Oops... {auth.error.message}</div>;\\n  }\\n  if (!auth.isAuthenticated) {\\n    let originPath = window.location.pathname;\\n    auth.signinRedirect({\\n      redirect_uri: process.env.REACT_APP_PROJECT_URL.concat(originPath),\\n    });\\n  }\\n\\n  if (auth.isAuthenticated) {\\n    window.history.replaceState({}, document.title, window.location.pathname);\\n    return <>{children}</>;\\n  }\\n};\\n\\nexport default PrivateRoute;\\n\\n```\\n\\n- This code defines a React component called PrivateRoute that serves as a wrapper for protecting certain routes in your application based on authentication status. \\n\\n- The PrivateRoute component takes a children prop, which represents the content that should be rendered if the user is authenticated.\\n\\n- Switch statement checks the activeNavigator property in the authentication context. If the user is in the process of a silent sign-in or sign-out redirect, it displays a corresponding message.\\n\\n- If the authentication context is still loading, the component returns an empty div (essentially doing nothing until authentication data is available).\\n\\n- If the user is not authenticated, it initiates a redirection to the authentication server using the signinRedirect method. It also captures the current path to redirect the user back to the intended page after authentication.\\n\\n- If the user is authenticated, it updates the browser history to remove sensitive information and renders the original children content.\\n\\n4. docker/\\n\\n```\\n|_docker\\n    |_realm-config\\n            |_jhipster-realm.json\\n    |_keycloak.yml\\n```\\n\\n- The Docker directory houses a Docker Compose configuration for Keycloak. This configuration initiates a Keycloak container that serves as the authentication server for our React application.\\n\\n- Within the docker/realm-config directory, there is a JSON-formatted realm configuration. This information, presented in JSON format, is essential for our React application as it serves as the OIDC (OpenID Connect) configuration.\\n\\n\\n### \ud83d\udea6 Getting Started\\n\\n1. Start the keycloak server\\n```\\nnpm run docker:keycloak:up\\n```\\n\\n2. Install dependencies for the first time.\\n```\\nnpm install\\n```\\n\\n3. Start you React application\\n```\\nnpm start\\n```\\n\\n### \ud83d\udcf8 Example images in action\\n\\n1. Home page of the React application generated via WeDAA.\\n\\n   ![Home page](https://i.imgur.com/WPwAEL9.png)\\n\\n2. Login Page for the React application powered by keycloak (click on the sign in button to land on this page, by default two users are provided [user,admin]; password is same as username).\\n\\n   ![Login Page](https://i.imgur.com/betJU5z.png)\\n\\n3. Home page after sucessful Login.\\n\\n   ![Logged In Home page](https://i.imgur.com/RuRXzHs.png)\\n\\n## \u2728 Conclusion\\n\\nCongratulations! \ud83c\udf89 You\'ve successfully navigated the realm of securing your React applications with the formidable duo of Keycloak and `react-oidc-context`. As you embark on your coding journey, armed with a fortified understanding of authentication and authorization, here\'s a recap of your key accomplishments:\\n\\n- Seamlessly integrated Keycloak as the authentication and authorization powerhouse.\\n- Leveraged the elegance of `react-oidc-context` to bridge the realms of React and OpenID Connect.\\n- Initiated a secure React application that not only prioritizes user experience but also champions data protection.\\n\\n### \ud83d\ude80 Quick Dive\\n\\nBefore you go, let\'s take one last glance at the live example you\'ve created. Head over to [**app.wedaa.tech**](https://app.wedaa.tech/) and witness your React application in action. From dynamic prototyping to authentication magic, your creation stands as a testament to your development prowess.\\n\\n### \ud83d\udee0\ufe0f Further Exploration\\n\\nAs you continue your coding adventures, explore the depths of the generated code. Whether it\'s delving into the intricacies of `src/index.js`, configuring environment variables in `.env`, or understanding the protective dance of `src/config/auth/privateRoute.js`, every line of code tells a story of security, creativity, and innovation.\\n\\n### \ud83c\udf10 Beyond the Horizon\\n\\nFor more insights and documentation, sail over to the [**WeDAA Documentation**](https://www.wedaa.tech/docs/introduction/what-is-wedaa/) and explore the GitHub repository at [**github.com/wedaa-tech**](https://github.com/wedaa-tech). Your journey doesn\'t end here \u2013 it\'s a launching pad for future projects, collaborations, and secure web development endeavors.\\n\\n## \ud83d\ude80 Ready, Set, Code!\\n\\nArmed with the knowledge and hands-on experience gained in this blog post, you\'re now equipped to conquer the world of React security. Start your engines, dive into the code, and let your creativity unfold. Happy coding, and may your React applications always be secure and splendid! \ud83c\udf1f"},{"id":"/2023/11/11/boilerplate-to-scaffolding","metadata":{"permalink":"/docs/blog/2023/11/11/boilerplate-to-scaffolding","source":"@site/blog/2023-11-11-boilerplate-to-scaffolding.md","title":"Transitioning from Boilerplate Development to Scaffolding Frameworks","description":"Transitioning from Boilerplate Development to Scaffolding Frameworks","date":"2023-11-11T00:00:00.000Z","formattedDate":"November 11, 2023","tags":[{"label":"prototyping","permalink":"/docs/blog/tags/prototyping"},{"label":"boilerplate","permalink":"/docs/blog/tags/boilerplate"}],"readingTime":1.95,"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"Transitioning from Boilerplate Development to Scaffolding Frameworks","description":"Transitioning from Boilerplate Development to Scaffolding Frameworks","image":"https://www.wedaa.tech/docs/img/first-blog-post.png","tags":["prototyping","boilerplate"],"date":"2023-11-11T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"Securing React applications with Keycloak","permalink":"/docs/blog/2023/12/26/Intergating-keycloak-with-react-app"}},"content":"In our ever-evolving tech landscape, we continually encounter new tools and technologies for constructing common software structures. With technology\'s daily progress, we witness fresh parameters and approaches applied to our existing setups.\\n \\nTo draw a parallel, consider the preparation of a delectable Biryani. The first step is to gather the right ingredients before diving into cooking. Spices, curd, salt, rice, and, of course, gasoline are essential. Most of these ingredients remain constant for everyone, while the art of cooking is what distinguishes one chef from another. Given that the ingredients remain the same, isn\'t it impractical to painstakingly prepare them from scratch each time we crave Biryani? It certainly is.\\n \\nIn contrast to the culinary world, in software engineering, we often find ourselves writing and configuring all components from scratch each time we embark on building a software solution.\\n \\nLet\'s consider a hypothetical scenario in software engineering: creating a full-stack application. It entails the development of numerous microservices, handling discovery, gateway, and inter-service communication. Additionally, we must set up logging, observability, security, and privacy mechanisms. Now, ponder this: countless others have undertaken these exact same tasks tens of thousands of times. Isn\'t it time to rethink our approach and prepare and assemble common technical components in advance, much like having essential spices ready when cooking Biryani.\\n \\nStarting from scratch each time leads to complications, extended development timelines, and monotony. As a software project expands and requires more boilerplate code, a developer\'s workload becomes increasingly burdensome. We must simultaneously ensure a solid foundation for our application\'s architecture. So, the question arises: where do we seek a solution? The answer lies in a scaffolding platform, where we build common components once and assemble them as needed.\\n \\nScaffolding represents a modern approach to generating the common building blocks of an application and configuring them to meet the software requirements. An effective scaffold might encompass features such as login and registration pages, service and server connections, routing, discovery, model templates, controllers, security, privacy, and observability mechanisms.\\n \\nThe next time you embark on application development, consider WeDAA, a platform designed for rapid prototyping and scaffolding of technologies and applications.\\n \\nWhat You\'ll Achieve:\\n \\nExpedited proposal development.\\nUnified systems for design, configurations, and asset control.\\nEnhanced security and privacy standards right from the start.\\nMore time to focus on your unique business case rather than common tasks.\\""}]}')}}]);